{"ast":null,"code":"// services/ai/perplexity.service.ts\nimport axios from 'axios';\nconst PERPLEXITY_API_URL = 'https://api.perplexity.ai/chat/completions';\n\n// Helper function to get API key dynamically\nconst getPerplexityApiKey = () => {\n  return process.env.REACT_APP_PERPLEXITY_API_KEY;\n};\nexport class PerplexityService {\n  async delay(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n  async makeRequest(messages, retryCount = 0) {\n    console.log('Making Perplexity API request...');\n    const apiKey = getPerplexityApiKey();\n    console.log('API Key exists:', !!apiKey);\n    console.log('API Key value:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined');\n    console.log('Messages length:', messages.length);\n    if (!apiKey) {\n      console.error('Environment variables:', {\n        REACT_APP_PERPLEXITY_API_KEY: process.env.REACT_APP_PERPLEXITY_API_KEY,\n        allEnvKeys: Object.keys(process.env).filter(key => key.startsWith('REACT_APP_'))\n      });\n      throw new Error('Perplexity API key is not configured. Please check your .env file.');\n    }\n    try {\n      const requestBody = {\n        model: 'sonar-pro',\n        messages,\n        temperature: 0.2,\n        max_tokens: 4000\n      };\n      console.log('Request body prepared, making API call...');\n      const response = await axios.post(PERPLEXITY_API_URL, requestBody, {\n        headers: {\n          'Authorization': `Bearer ${apiKey}`,\n          'Content-Type': 'application/json'\n        },\n        timeout: 120000 // 2 minute timeout\n      });\n      console.log('API response received, status:', response.status);\n      console.log('Response data structure:', Object.keys(response.data));\n      if (!response.data.choices || !response.data.choices[0]) {\n        throw new Error('Invalid API response structure');\n      }\n      return response.data.choices[0].message.content;\n    } catch (error) {\n      var _error$response, _error$response2, _error$response3, _error$response4, _error$response5, _error$response6, _error$response6$data, _error$response6$data2;\n      console.error('Perplexity API error details:', {\n        message: error.message,\n        response: (_error$response = error.response) === null || _error$response === void 0 ? void 0 : _error$response.data,\n        status: (_error$response2 = error.response) === null || _error$response2 === void 0 ? void 0 : _error$response2.status,\n        isTimeout: error.code === 'ECONNABORTED',\n        retryCount\n      });\n\n      // Retry logic for specific errors\n      const maxRetries = 2;\n      const shouldRetry = retryCount < maxRetries && (((_error$response3 = error.response) === null || _error$response3 === void 0 ? void 0 : _error$response3.status) === 429 ||\n      // Rate limit\n      ((_error$response4 = error.response) === null || _error$response4 === void 0 ? void 0 : _error$response4.status) === 503 ||\n      // Service unavailable\n      ((_error$response5 = error.response) === null || _error$response5 === void 0 ? void 0 : _error$response5.status) === 504 ||\n      // Gateway timeout\n      error.code === 'ECONNABORTED' ||\n      // Request timeout\n      error.code === 'ENOTFOUND' ||\n      // DNS issues\n      error.code === 'ECONNREFUSED' // Connection refused\n      );\n      if (shouldRetry) {\n        const delayMs = Math.pow(2, retryCount) * 1000; // Exponential backoff: 1s, 2s\n        console.log(`Retrying in ${delayMs}ms... (attempt ${retryCount + 1}/${maxRetries})`);\n        await this.delay(delayMs);\n        return this.makeRequest(messages, retryCount + 1);\n      }\n      if (error.code === 'ECONNABORTED') {\n        throw new Error('Request timed out - please try again');\n      }\n      throw new Error(((_error$response6 = error.response) === null || _error$response6 === void 0 ? void 0 : (_error$response6$data = _error$response6.data) === null || _error$response6$data === void 0 ? void 0 : (_error$response6$data2 = _error$response6$data.error) === null || _error$response6$data2 === void 0 ? void 0 : _error$response6$data2.message) || error.message || 'Failed to get research data');\n    }\n  }\n  async generateResearch(keyword) {\n    console.time('Perplexity Research Time');\n    console.log('Starting Perplexity research for:', keyword);\n    const systemPrompt = `You are an expert SEO research analyst focused on E-E-A-T (Experience, Expertise, Authoritativeness, Trustworthiness). \n    Your research will be used to create content that ranks well on Google by demonstrating real expertise and authority.\n    Always provide specific, verifiable data with sources. Focus on unique insights that demonstrate deep understanding.`;\n    const userPrompt = `Research \"${keyword}\" and provide comprehensive information in JSON format.\n\nInclude:\n1. Definition and overview\n2. Current trends and statistics\n3. Common questions people ask\n4. Related topics and applications\n5. Key challenges and opportunities\n\nFormat as JSON:\n{\n  \"definition\": \"Clear definition of ${keyword}\",\n  \"overview\": \"Comprehensive overview\",\n  \"currentTrends\": [\"trend1\", \"trend2\", \"trend3\"],\n  \"statistics\": [\"stat1 with source\", \"stat2 with source\"],\n  \"commonQuestions\": [\n    {\"question\": \"What is ${keyword}?\", \"answer\": \"detailed answer\"},\n    {\"question\": \"How does ${keyword} work?\", \"answer\": \"detailed answer\"}\n  ],\n  \"relatedTopics\": [\"topic1\", \"topic2\", \"topic3\"],\n  \"applications\": [\"application1\", \"application2\"],\n  \"challenges\": [\"challenge1\", \"challenge2\"],\n  \"opportunities\": [\"opportunity1\", \"opportunity2\"],\n  \"futureOutlook\": \"Analysis of future trends\"\n}\n\nReturn only valid JSON.`;\n    const messages = [{\n      role: 'system',\n      content: systemPrompt\n    }, {\n      role: 'user',\n      content: userPrompt\n    }];\n    const response = await this.makeRequest(messages);\n    console.timeEnd('Perplexity Research Time');\n    console.log('Perplexity response received, length:', response.length);\n    try {\n      const researchData = JSON.parse(response);\n      console.log('Research data parsed successfully');\n      return researchData;\n    } catch (parseError) {\n      console.timeEnd('Perplexity Research Time');\n      console.error('Failed to parse research response:', parseError);\n      console.log('Raw response:', response.substring(0, 500) + '...');\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        return JSON.parse(jsonMatch[0]);\n      }\n      throw new Error('Failed to parse research data');\n    }\n  }\n  async generateBlog(keyword, research) {\n    console.log('Generating SEO-optimized blog for:', keyword);\n    console.log('Research data:', research);\n    const systemPrompt = `You are an expert SEO content writer who creates highly engaging, authoritative content that ranks well on Google. \n    You follow E-E-A-T principles and write content that demonstrates real expertise, experience, authority, and trustworthiness.\n    Your content is comprehensive, well-structured, and naturally incorporates keywords for optimal SEO performance.\n    \n    IMPORTANT: Write at an 8th-grade reading level using:\n    - Short sentences (15-20 words max)\n    - Simple, common words\n    - Active voice\n    - Clear, direct language\n    - One idea per sentence\n    - Avoid jargon unless necessary (and explain it when used)`;\n\n    // Build research summary from available data\n    let researchSummary = '';\n    if (research) {\n      if (research.definition) researchSummary += `\\nDefinition: ${research.definition}`;\n      if (research.overview) researchSummary += `\\nOverview: ${research.overview}`;\n      if (research.currentTrends) researchSummary += `\\nTrends: ${Array.isArray(research.currentTrends) ? research.currentTrends.join(', ') : research.currentTrends}`;\n      if (research.statistics) researchSummary += `\\nStatistics: ${JSON.stringify(research.statistics).slice(0, 500)}`;\n      if (research.commonQuestions) researchSummary += `\\nCommon Questions: ${JSON.stringify(research.commonQuestions).slice(0, 500)}`;\n      if (research.applications) researchSummary += `\\nApplications: ${Array.isArray(research.applications) ? research.applications.join(', ') : research.applications}`;\n    }\n    if (!researchSummary) {\n      researchSummary = JSON.stringify(research, null, 2).slice(0, 2000);\n    }\n    const userPrompt = `Create a comprehensive, SEO-optimized blog post about \"${keyword}\" using the provided research data.\n\nRESEARCH DATA:${researchSummary}\n\nBLOG POST REQUIREMENTS:\n\n1. Create a blog post that is 1,500-2,000 words long\n2. Include an SEO-optimized title that naturally includes \"${keyword}\"\n3. Write a compelling meta description (155-160 characters)\n4. Structure with:\n   - Engaging introduction with a hook\n   - 5-7 main sections with H2 headings\n   - Subsections with H3 headings where appropriate\n   - Conclusion with clear call-to-action\n\n5. SEO Optimization:\n   - Use \"${keyword}\" naturally 5-7 times throughout\n   - Include semantic variations and related terms\n   - Target potential featured snippets with clear, concise answers\n   - Write in an easy-to-read style (8th-grade level)\n\n6. READABILITY REQUIREMENTS (8th Grade Level):\n   - Use short sentences (15-20 words maximum)\n   - Choose simple, everyday words over complex ones\n   - Write in active voice (\"We tested\" not \"It was tested\")\n   - Break complex ideas into simple steps\n   - Use transition words (First, Next, However, Therefore)\n   - Define technical terms in simple language\n   - Use concrete examples to explain abstract concepts\n\n7. Demonstrate E-E-A-T:\n   - Show expertise through accurate information\n   - Include statistics and data points from the research\n   - Reference authoritative sources\n   - Provide practical, actionable advice\n\n8. Engagement:\n   - Use short paragraphs (2-3 sentences)\n   - Include bullet points and lists\n   - Add examples and analogies\n   - Keep the tone conversational but professional\n   - Ask rhetorical questions to engage readers\n   - Use \"you\" to speak directly to the reader\n\nFORMAT YOUR RESPONSE AS JSON:\n{\n  \"title\": \"SEO-optimized title with keyword\",\n  \"metaDescription\": \"Compelling meta description 155-160 characters with keyword\",\n  \"content\": \"Full blog post in Markdown format with ## for H2 and ### for H3 headings\",\n  \"wordCount\": 1800,\n  \"readingTime\": 8,\n  \"targetKeywords\": [\"main keyword\", \"related keyword 1\", \"related keyword 2\"],\n  \"readabilityScore\": \"Grade 8\"\n}\n\nRemember: Write clearly and simply. If a 13-year-old can understand it, you're doing it right.`;\n    const messages = [{\n      role: 'system',\n      content: systemPrompt\n    }, {\n      role: 'user',\n      content: userPrompt\n    }];\n    const response = await this.makeRequest(messages);\n    try {\n      console.log('Raw response length:', response.length);\n      console.log('Response preview:', response.substring(0, 500));\n      console.log('Character at position 509:', response.charCodeAt(509));\n      console.log('Context around position 509:', response.substring(500, 520));\n\n      // Try a more aggressive approach - parse the response structure manually\n      let jsonString = response.trim();\n\n      // If the response has markdown code blocks, extract the JSON from them\n      const codeBlockMatch = jsonString.match(/```(?:json)?\\s*(\\{[\\s\\S]*?\\})\\s*```/);\n      if (codeBlockMatch) {\n        jsonString = codeBlockMatch[1];\n      }\n\n      // Extract fields using regex instead of trying to parse potentially broken JSON\n      const extractField = (fieldName, isLongText = false) => {\n        const pattern = isLongText ? new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([\\\\s\\\\S]*?)(?=\",\\\\s*\"|\"\\\\s*}|$)`, 'i') : new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([^\"]*)\"`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          let value = match[1];\n          // Clean up the extracted value\n          value = value.replace(/\\\\\"/g, '\"'); // Unescape quotes\n          value = value.replace(/\\\\\\\\/g, '\\\\'); // Unescape backslashes\n          if (!isLongText) {\n            value = value.replace(/[\\n\\r\\t]/g, ' ').trim();\n          }\n          return value;\n        }\n        return '';\n      };\n      const extractArray = fieldName => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\\\\[([^\\\\]]*)]`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          return match[1].split(',').map(s => s.trim().replace(/^[\"']|[\"']$/g, '')).filter(s => s);\n        }\n        return [];\n      };\n      const extractNumber = fieldName => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*(\\\\d+)`, 'i');\n        const match = jsonString.match(pattern);\n        return match && match[1] ? parseInt(match[1]) : 0;\n      };\n\n      // Manually construct the blog data object\n      const blogData = {\n        title: extractField('title') || `Expert Guide to ${keyword}`,\n        metaDescription: extractField('metaDescription') || `Comprehensive guide about ${keyword}. Learn everything you need to know.`,\n        content: extractField('content', true) || `# ${keyword}\\n\\nContent generation in progress...`,\n        wordCount: extractNumber('wordCount') || 1500,\n        readingTime: extractNumber('readingTime') || 8,\n        targetKeywords: extractArray('targetKeywords').length > 0 ? extractArray('targetKeywords') : [keyword],\n        readabilityScore: extractField('readabilityScore') || 'Grade 8'\n      };\n\n      // Clean the content field to ensure it's valid markdown\n      blogData.content = blogData.content.replace(/\\\\n/g, '\\n').replace(/\\\\r/g, '\\r').replace(/\\\\t/g, '\\t').replace(/\\n{3,}/g, '\\n\\n') // Limit consecutive newlines\n      .trim();\n\n      // Ensure content has proper markdown structure\n      if (!blogData.content.includes('#')) {\n        blogData.content = `# ${blogData.title}\\n\\n${blogData.content}`;\n      }\n      console.log('Successfully constructed blog data');\n      return blogData;\n    } catch (parseError) {\n      var _parseError$message$m;\n      console.error('Failed to parse blog response:', parseError);\n      console.error('Parse error details:', {\n        message: parseError.message,\n        position: (_parseError$message$m = parseError.message.match(/position (\\d+)/)) === null || _parseError$message$m === void 0 ? void 0 : _parseError$message$m[1],\n        response: response.substring(0, 600) + '...'\n      });\n\n      // Try to extract JSON from the response\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        try {\n          let cleanedExtract = jsonMatch[0];\n\n          // Apply the same cleaning logic as above\n          cleanedExtract = cleanedExtract.replace(/\"content\"\\s*:\\s*\"([\\s\\S]*?)\"\\s*(?=,\\s*\"|\\s*\\})/g, (match, content) => {\n            let fixed = content;\n            fixed = fixed.replace(/\\\\/g, '\\\\\\\\');\n            fixed = fixed.replace(/([^\\\\])\"/g, '$1\\\\\"');\n            fixed = fixed.replace(/^\"/g, '\\\\\"');\n            fixed = fixed.replace(/([^\\\\])\\n/g, '$1\\\\n');\n            fixed = fixed.replace(/^\\n/g, '\\\\n');\n            fixed = fixed.replace(/([^\\\\])\\r/g, '$1\\\\r');\n            fixed = fixed.replace(/^\\r/g, '\\\\r');\n            fixed = fixed.replace(/([^\\\\])\\t/g, '$1\\\\t');\n            fixed = fixed.replace(/^\\t/g, '\\\\t');\n            return `\"content\": \"${fixed}\"`;\n          });\n\n          // Clean other fields\n          cleanedExtract = cleanedExtract.replace(/\"(title|metaDescription)\"\\s*:\\s*\"([^\"\\\\]*(\\\\.[^\"\\\\]*)*)\"/g, (match, field, content) => {\n            const fixed = content.replace(/[\\n\\r\\t]/g, ' ').trim();\n            return `\"${field}\": \"${fixed}\"`;\n          });\n\n          // Remove trailing commas and control characters\n          cleanedExtract = cleanedExtract.replace(/,\\s*([}\\]])/g, '$1');\n          cleanedExtract = cleanedExtract.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g, '');\n          const extracted = JSON.parse(cleanedExtract);\n          if (!extracted.wordCount) extracted.wordCount = 1500;\n          if (!extracted.readingTime) extracted.readingTime = 8;\n          if (!extracted.targetKeywords) extracted.targetKeywords = [keyword];\n          if (!extracted.readabilityScore) extracted.readabilityScore = \"Grade 8\";\n          return extracted;\n        } catch (e) {\n          console.error('Failed to parse extracted JSON:', e);\n        }\n      }\n      throw new Error('Failed to parse blog data: ' + parseError.message);\n    }\n  }\n}\nexport const perplexityService = new PerplexityService();","map":{"version":3,"names":["axios","PERPLEXITY_API_URL","getPerplexityApiKey","process","env","REACT_APP_PERPLEXITY_API_KEY","PerplexityService","delay","ms","Promise","resolve","setTimeout","makeRequest","messages","retryCount","console","log","apiKey","substring","length","error","allEnvKeys","Object","keys","filter","key","startsWith","Error","requestBody","model","temperature","max_tokens","response","post","headers","timeout","status","data","choices","message","content","_error$response","_error$response2","_error$response3","_error$response4","_error$response5","_error$response6","_error$response6$data","_error$response6$data2","isTimeout","code","maxRetries","shouldRetry","delayMs","Math","pow","generateResearch","keyword","time","systemPrompt","userPrompt","role","timeEnd","researchData","JSON","parse","parseError","jsonMatch","match","generateBlog","research","researchSummary","definition","overview","currentTrends","Array","isArray","join","statistics","stringify","slice","commonQuestions","applications","charCodeAt","jsonString","trim","codeBlockMatch","extractField","fieldName","isLongText","pattern","RegExp","value","replace","extractArray","split","map","s","extractNumber","parseInt","blogData","title","metaDescription","wordCount","readingTime","targetKeywords","readabilityScore","includes","_parseError$message$m","position","cleanedExtract","fixed","field","extracted","e","perplexityService"],"sources":["/Users/will/Content Creation App/src/services/ai/perplexity.service.ts"],"sourcesContent":["// services/ai/perplexity.service.ts\nimport axios from 'axios';\nimport { ResearchContent } from '../../types/project.types';\n\nconst PERPLEXITY_API_URL = 'https://api.perplexity.ai/chat/completions';\n\n// Helper function to get API key dynamically\nconst getPerplexityApiKey = () => {\n  return process.env.REACT_APP_PERPLEXITY_API_KEY;\n};\n\ninterface PerplexityResponse {\n  id: string;\n  model: string;\n  choices: Array<{\n    message: {\n      role: string;\n      content: string;\n    };\n    finish_reason: string;\n  }>;\n}\n\nexport class PerplexityService {\n  private async delay(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  private async makeRequest(messages: any[], retryCount: number = 0): Promise<string> {\n    console.log('Making Perplexity API request...');\n    const apiKey = getPerplexityApiKey();\n    console.log('API Key exists:', !!apiKey);\n    console.log('API Key value:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined');\n    console.log('Messages length:', messages.length);\n    \n    if (!apiKey) {\n      console.error('Environment variables:', {\n        REACT_APP_PERPLEXITY_API_KEY: process.env.REACT_APP_PERPLEXITY_API_KEY,\n        allEnvKeys: Object.keys(process.env).filter(key => key.startsWith('REACT_APP_'))\n      });\n      throw new Error('Perplexity API key is not configured. Please check your .env file.');\n    }\n    \n    try {\n      const requestBody = {\n        model: 'sonar-pro',\n        messages,\n        temperature: 0.2,\n        max_tokens: 4000,\n      };\n      \n      console.log('Request body prepared, making API call...');\n      \n      const response = await axios.post<PerplexityResponse>(\n        PERPLEXITY_API_URL,\n        requestBody,\n        {\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'Content-Type': 'application/json',\n          },\n          timeout: 120000, // 2 minute timeout\n        }\n      );\n\n      console.log('API response received, status:', response.status);\n      console.log('Response data structure:', Object.keys(response.data));\n      \n      if (!response.data.choices || !response.data.choices[0]) {\n        throw new Error('Invalid API response structure');\n      }\n\n      return response.data.choices[0].message.content;\n    } catch (error: any) {\n      console.error('Perplexity API error details:', {\n        message: error.message,\n        response: error.response?.data,\n        status: error.response?.status,\n        isTimeout: error.code === 'ECONNABORTED',\n        retryCount\n      });\n      \n      // Retry logic for specific errors\n      const maxRetries = 2;\n      const shouldRetry = retryCount < maxRetries && (\n        error.response?.status === 429 || // Rate limit\n        error.response?.status === 503 || // Service unavailable\n        error.response?.status === 504 || // Gateway timeout\n        error.code === 'ECONNABORTED' ||  // Request timeout\n        error.code === 'ENOTFOUND' ||      // DNS issues\n        error.code === 'ECONNREFUSED'      // Connection refused\n      );\n      \n      if (shouldRetry) {\n        const delayMs = Math.pow(2, retryCount) * 1000; // Exponential backoff: 1s, 2s\n        console.log(`Retrying in ${delayMs}ms... (attempt ${retryCount + 1}/${maxRetries})`);\n        await this.delay(delayMs);\n        return this.makeRequest(messages, retryCount + 1);\n      }\n      \n      if (error.code === 'ECONNABORTED') {\n        throw new Error('Request timed out - please try again');\n      }\n      \n      throw new Error(error.response?.data?.error?.message || error.message || 'Failed to get research data');\n    }\n  }\n\n  async generateResearch(keyword: string): Promise<ResearchContent> {\n    console.time('Perplexity Research Time');\n    console.log('Starting Perplexity research for:', keyword);\n    \n    const systemPrompt = `You are an expert SEO research analyst focused on E-E-A-T (Experience, Expertise, Authoritativeness, Trustworthiness). \n    Your research will be used to create content that ranks well on Google by demonstrating real expertise and authority.\n    Always provide specific, verifiable data with sources. Focus on unique insights that demonstrate deep understanding.`;\n\n    const userPrompt = `Research \"${keyword}\" and provide comprehensive information in JSON format.\n\nInclude:\n1. Definition and overview\n2. Current trends and statistics\n3. Common questions people ask\n4. Related topics and applications\n5. Key challenges and opportunities\n\nFormat as JSON:\n{\n  \"definition\": \"Clear definition of ${keyword}\",\n  \"overview\": \"Comprehensive overview\",\n  \"currentTrends\": [\"trend1\", \"trend2\", \"trend3\"],\n  \"statistics\": [\"stat1 with source\", \"stat2 with source\"],\n  \"commonQuestions\": [\n    {\"question\": \"What is ${keyword}?\", \"answer\": \"detailed answer\"},\n    {\"question\": \"How does ${keyword} work?\", \"answer\": \"detailed answer\"}\n  ],\n  \"relatedTopics\": [\"topic1\", \"topic2\", \"topic3\"],\n  \"applications\": [\"application1\", \"application2\"],\n  \"challenges\": [\"challenge1\", \"challenge2\"],\n  \"opportunities\": [\"opportunity1\", \"opportunity2\"],\n  \"futureOutlook\": \"Analysis of future trends\"\n}\n\nReturn only valid JSON.`;\n\n    const messages = [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: userPrompt }\n    ];\n\n    const response = await this.makeRequest(messages);\n    console.timeEnd('Perplexity Research Time');\n    console.log('Perplexity response received, length:', response.length);\n    \n    try {\n      const researchData = JSON.parse(response);\n      console.log('Research data parsed successfully');\n      return researchData as ResearchContent;\n    } catch (parseError) {\n      console.timeEnd('Perplexity Research Time');\n      console.error('Failed to parse research response:', parseError);\n      console.log('Raw response:', response.substring(0, 500) + '...');\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        return JSON.parse(jsonMatch[0]) as ResearchContent;\n      }\n      throw new Error('Failed to parse research data');\n    }\n  }\n\n  async generateBlog(keyword: string, research: any): Promise<any> {\n    console.log('Generating SEO-optimized blog for:', keyword);\n    console.log('Research data:', research);\n\n    const systemPrompt = `You are an expert SEO content writer who creates highly engaging, authoritative content that ranks well on Google. \n    You follow E-E-A-T principles and write content that demonstrates real expertise, experience, authority, and trustworthiness.\n    Your content is comprehensive, well-structured, and naturally incorporates keywords for optimal SEO performance.\n    \n    IMPORTANT: Write at an 8th-grade reading level using:\n    - Short sentences (15-20 words max)\n    - Simple, common words\n    - Active voice\n    - Clear, direct language\n    - One idea per sentence\n    - Avoid jargon unless necessary (and explain it when used)`;\n\n    // Build research summary from available data\n    let researchSummary = '';\n    if (research) {\n      if (research.definition) researchSummary += `\\nDefinition: ${research.definition}`;\n      if (research.overview) researchSummary += `\\nOverview: ${research.overview}`;\n      if (research.currentTrends) researchSummary += `\\nTrends: ${Array.isArray(research.currentTrends) ? research.currentTrends.join(', ') : research.currentTrends}`;\n      if (research.statistics) researchSummary += `\\nStatistics: ${JSON.stringify(research.statistics).slice(0, 500)}`;\n      if (research.commonQuestions) researchSummary += `\\nCommon Questions: ${JSON.stringify(research.commonQuestions).slice(0, 500)}`;\n      if (research.applications) researchSummary += `\\nApplications: ${Array.isArray(research.applications) ? research.applications.join(', ') : research.applications}`;\n    }\n\n    if (!researchSummary) {\n      researchSummary = JSON.stringify(research, null, 2).slice(0, 2000);\n    }\n\n    const userPrompt = `Create a comprehensive, SEO-optimized blog post about \"${keyword}\" using the provided research data.\n\nRESEARCH DATA:${researchSummary}\n\nBLOG POST REQUIREMENTS:\n\n1. Create a blog post that is 1,500-2,000 words long\n2. Include an SEO-optimized title that naturally includes \"${keyword}\"\n3. Write a compelling meta description (155-160 characters)\n4. Structure with:\n   - Engaging introduction with a hook\n   - 5-7 main sections with H2 headings\n   - Subsections with H3 headings where appropriate\n   - Conclusion with clear call-to-action\n\n5. SEO Optimization:\n   - Use \"${keyword}\" naturally 5-7 times throughout\n   - Include semantic variations and related terms\n   - Target potential featured snippets with clear, concise answers\n   - Write in an easy-to-read style (8th-grade level)\n\n6. READABILITY REQUIREMENTS (8th Grade Level):\n   - Use short sentences (15-20 words maximum)\n   - Choose simple, everyday words over complex ones\n   - Write in active voice (\"We tested\" not \"It was tested\")\n   - Break complex ideas into simple steps\n   - Use transition words (First, Next, However, Therefore)\n   - Define technical terms in simple language\n   - Use concrete examples to explain abstract concepts\n\n7. Demonstrate E-E-A-T:\n   - Show expertise through accurate information\n   - Include statistics and data points from the research\n   - Reference authoritative sources\n   - Provide practical, actionable advice\n\n8. Engagement:\n   - Use short paragraphs (2-3 sentences)\n   - Include bullet points and lists\n   - Add examples and analogies\n   - Keep the tone conversational but professional\n   - Ask rhetorical questions to engage readers\n   - Use \"you\" to speak directly to the reader\n\nFORMAT YOUR RESPONSE AS JSON:\n{\n  \"title\": \"SEO-optimized title with keyword\",\n  \"metaDescription\": \"Compelling meta description 155-160 characters with keyword\",\n  \"content\": \"Full blog post in Markdown format with ## for H2 and ### for H3 headings\",\n  \"wordCount\": 1800,\n  \"readingTime\": 8,\n  \"targetKeywords\": [\"main keyword\", \"related keyword 1\", \"related keyword 2\"],\n  \"readabilityScore\": \"Grade 8\"\n}\n\nRemember: Write clearly and simply. If a 13-year-old can understand it, you're doing it right.`;\n\n    const messages = [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: userPrompt }\n    ];\n\n    const response = await this.makeRequest(messages);\n    \n    try {\n      console.log('Raw response length:', response.length);\n      console.log('Response preview:', response.substring(0, 500));\n      console.log('Character at position 509:', response.charCodeAt(509));\n      console.log('Context around position 509:', response.substring(500, 520));\n      \n      // Try a more aggressive approach - parse the response structure manually\n      let jsonString = response.trim();\n      \n      // If the response has markdown code blocks, extract the JSON from them\n      const codeBlockMatch = jsonString.match(/```(?:json)?\\s*(\\{[\\s\\S]*?\\})\\s*```/);\n      if (codeBlockMatch) {\n        jsonString = codeBlockMatch[1];\n      }\n      \n      // Extract fields using regex instead of trying to parse potentially broken JSON\n      const extractField = (fieldName: string, isLongText: boolean = false): string => {\n        const pattern = isLongText \n          ? new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([\\\\s\\\\S]*?)(?=\",\\\\s*\"|\"\\\\s*}|$)`, 'i')\n          : new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([^\"]*)\"`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          let value = match[1];\n          // Clean up the extracted value\n          value = value.replace(/\\\\\"/g, '\"'); // Unescape quotes\n          value = value.replace(/\\\\\\\\/g, '\\\\'); // Unescape backslashes\n          if (!isLongText) {\n            value = value.replace(/[\\n\\r\\t]/g, ' ').trim();\n          }\n          return value;\n        }\n        return '';\n      };\n      \n      const extractArray = (fieldName: string): string[] => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\\\\[([^\\\\]]*)]`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          return match[1]\n            .split(',')\n            .map(s => s.trim().replace(/^[\"']|[\"']$/g, ''))\n            .filter(s => s);\n        }\n        return [];\n      };\n      \n      const extractNumber = (fieldName: string): number => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*(\\\\d+)`, 'i');\n        const match = jsonString.match(pattern);\n        return match && match[1] ? parseInt(match[1]) : 0;\n      };\n      \n      // Manually construct the blog data object\n      const blogData = {\n        title: extractField('title') || `Expert Guide to ${keyword}`,\n        metaDescription: extractField('metaDescription') || `Comprehensive guide about ${keyword}. Learn everything you need to know.`,\n        content: extractField('content', true) || `# ${keyword}\\n\\nContent generation in progress...`,\n        wordCount: extractNumber('wordCount') || 1500,\n        readingTime: extractNumber('readingTime') || 8,\n        targetKeywords: extractArray('targetKeywords').length > 0 ? extractArray('targetKeywords') : [keyword],\n        readabilityScore: extractField('readabilityScore') || 'Grade 8'\n      };\n      \n      // Clean the content field to ensure it's valid markdown\n      blogData.content = blogData.content\n        .replace(/\\\\n/g, '\\n')\n        .replace(/\\\\r/g, '\\r')\n        .replace(/\\\\t/g, '\\t')\n        .replace(/\\n{3,}/g, '\\n\\n') // Limit consecutive newlines\n        .trim();\n      \n      // Ensure content has proper markdown structure\n      if (!blogData.content.includes('#')) {\n        blogData.content = `# ${blogData.title}\\n\\n${blogData.content}`;\n      }\n      \n      console.log('Successfully constructed blog data');\n      return blogData;\n    } catch (parseError: any) {\n      console.error('Failed to parse blog response:', parseError);\n      console.error('Parse error details:', {\n        message: parseError.message,\n        position: parseError.message.match(/position (\\d+)/)?.[1],\n        response: response.substring(0, 600) + '...'\n      });\n      \n      // Try to extract JSON from the response\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        try {\n          let cleanedExtract = jsonMatch[0];\n          \n          // Apply the same cleaning logic as above\n          cleanedExtract = cleanedExtract.replace(/\"content\"\\s*:\\s*\"([\\s\\S]*?)\"\\s*(?=,\\s*\"|\\s*\\})/g, (match, content) => {\n            let fixed = content;\n            fixed = fixed.replace(/\\\\/g, '\\\\\\\\');\n            fixed = fixed.replace(/([^\\\\])\"/g, '$1\\\\\"');\n            fixed = fixed.replace(/^\"/g, '\\\\\"');\n            fixed = fixed.replace(/([^\\\\])\\n/g, '$1\\\\n');\n            fixed = fixed.replace(/^\\n/g, '\\\\n');\n            fixed = fixed.replace(/([^\\\\])\\r/g, '$1\\\\r');\n            fixed = fixed.replace(/^\\r/g, '\\\\r');\n            fixed = fixed.replace(/([^\\\\])\\t/g, '$1\\\\t');\n            fixed = fixed.replace(/^\\t/g, '\\\\t');\n            return `\"content\": \"${fixed}\"`;\n          });\n          \n          // Clean other fields\n          cleanedExtract = cleanedExtract.replace(/\"(title|metaDescription)\"\\s*:\\s*\"([^\"\\\\]*(\\\\.[^\"\\\\]*)*)\"/g, (match, field, content) => {\n            const fixed = content.replace(/[\\n\\r\\t]/g, ' ').trim();\n            return `\"${field}\": \"${fixed}\"`;\n          });\n          \n          // Remove trailing commas and control characters\n          cleanedExtract = cleanedExtract.replace(/,\\s*([}\\]])/g, '$1');\n          cleanedExtract = cleanedExtract.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g, '');\n          \n          const extracted = JSON.parse(cleanedExtract);\n          if (!extracted.wordCount) extracted.wordCount = 1500;\n          if (!extracted.readingTime) extracted.readingTime = 8;\n          if (!extracted.targetKeywords) extracted.targetKeywords = [keyword];\n          if (!extracted.readabilityScore) extracted.readabilityScore = \"Grade 8\";\n          return extracted;\n        } catch (e) {\n          console.error('Failed to parse extracted JSON:', e);\n        }\n      }\n      throw new Error('Failed to parse blog data: ' + parseError.message);\n    }\n  }\n}\n\nexport const perplexityService = new PerplexityService();"],"mappings":"AAAA;AACA,OAAOA,KAAK,MAAM,OAAO;AAGzB,MAAMC,kBAAkB,GAAG,4CAA4C;;AAEvE;AACA,MAAMC,mBAAmB,GAAGA,CAAA,KAAM;EAChC,OAAOC,OAAO,CAACC,GAAG,CAACC,4BAA4B;AACjD,CAAC;AAcD,OAAO,MAAMC,iBAAiB,CAAC;EAC7B,MAAcC,KAAKA,CAACC,EAAU,EAAiB;IAC7C,OAAO,IAAIC,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAEF,EAAE,CAAC,CAAC;EACxD;EAEA,MAAcI,WAAWA,CAACC,QAAe,EAAEC,UAAkB,GAAG,CAAC,EAAmB;IAClFC,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC;IAC/C,MAAMC,MAAM,GAAGf,mBAAmB,CAAC,CAAC;IACpCa,OAAO,CAACC,GAAG,CAAC,iBAAiB,EAAE,CAAC,CAACC,MAAM,CAAC;IACxCF,OAAO,CAACC,GAAG,CAAC,gBAAgB,EAAEC,MAAM,GAAG,GAAGA,MAAM,CAACC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,GAAG,WAAW,CAAC;IACrFH,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAEH,QAAQ,CAACM,MAAM,CAAC;IAEhD,IAAI,CAACF,MAAM,EAAE;MACXF,OAAO,CAACK,KAAK,CAAC,wBAAwB,EAAE;QACtCf,4BAA4B,EAAEF,OAAO,CAACC,GAAG,CAACC,4BAA4B;QACtEgB,UAAU,EAAEC,MAAM,CAACC,IAAI,CAACpB,OAAO,CAACC,GAAG,CAAC,CAACoB,MAAM,CAACC,GAAG,IAAIA,GAAG,CAACC,UAAU,CAAC,YAAY,CAAC;MACjF,CAAC,CAAC;MACF,MAAM,IAAIC,KAAK,CAAC,oEAAoE,CAAC;IACvF;IAEA,IAAI;MACF,MAAMC,WAAW,GAAG;QAClBC,KAAK,EAAE,WAAW;QAClBhB,QAAQ;QACRiB,WAAW,EAAE,GAAG;QAChBC,UAAU,EAAE;MACd,CAAC;MAEDhB,OAAO,CAACC,GAAG,CAAC,2CAA2C,CAAC;MAExD,MAAMgB,QAAQ,GAAG,MAAMhC,KAAK,CAACiC,IAAI,CAC/BhC,kBAAkB,EAClB2B,WAAW,EACX;QACEM,OAAO,EAAE;UACP,eAAe,EAAE,UAAUjB,MAAM,EAAE;UACnC,cAAc,EAAE;QAClB,CAAC;QACDkB,OAAO,EAAE,MAAM,CAAE;MACnB,CACF,CAAC;MAEDpB,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEgB,QAAQ,CAACI,MAAM,CAAC;MAC9DrB,OAAO,CAACC,GAAG,CAAC,0BAA0B,EAAEM,MAAM,CAACC,IAAI,CAACS,QAAQ,CAACK,IAAI,CAAC,CAAC;MAEnE,IAAI,CAACL,QAAQ,CAACK,IAAI,CAACC,OAAO,IAAI,CAACN,QAAQ,CAACK,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,EAAE;QACvD,MAAM,IAAIX,KAAK,CAAC,gCAAgC,CAAC;MACnD;MAEA,OAAOK,QAAQ,CAACK,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACC,OAAO;IACjD,CAAC,CAAC,OAAOpB,KAAU,EAAE;MAAA,IAAAqB,eAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,qBAAA,EAAAC,sBAAA;MACnBjC,OAAO,CAACK,KAAK,CAAC,+BAA+B,EAAE;QAC7CmB,OAAO,EAAEnB,KAAK,CAACmB,OAAO;QACtBP,QAAQ,GAAAS,eAAA,GAAErB,KAAK,CAACY,QAAQ,cAAAS,eAAA,uBAAdA,eAAA,CAAgBJ,IAAI;QAC9BD,MAAM,GAAAM,gBAAA,GAAEtB,KAAK,CAACY,QAAQ,cAAAU,gBAAA,uBAAdA,gBAAA,CAAgBN,MAAM;QAC9Ba,SAAS,EAAE7B,KAAK,CAAC8B,IAAI,KAAK,cAAc;QACxCpC;MACF,CAAC,CAAC;;MAEF;MACA,MAAMqC,UAAU,GAAG,CAAC;MACpB,MAAMC,WAAW,GAAGtC,UAAU,GAAGqC,UAAU,KACzC,EAAAR,gBAAA,GAAAvB,KAAK,CAACY,QAAQ,cAAAW,gBAAA,uBAAdA,gBAAA,CAAgBP,MAAM,MAAK,GAAG;MAAI;MAClC,EAAAQ,gBAAA,GAAAxB,KAAK,CAACY,QAAQ,cAAAY,gBAAA,uBAAdA,gBAAA,CAAgBR,MAAM,MAAK,GAAG;MAAI;MAClC,EAAAS,gBAAA,GAAAzB,KAAK,CAACY,QAAQ,cAAAa,gBAAA,uBAAdA,gBAAA,CAAgBT,MAAM,MAAK,GAAG;MAAI;MAClChB,KAAK,CAAC8B,IAAI,KAAK,cAAc;MAAK;MAClC9B,KAAK,CAAC8B,IAAI,KAAK,WAAW;MAAS;MACnC9B,KAAK,CAAC8B,IAAI,KAAK,cAAc,CAAM;MAAA,CACpC;MAED,IAAIE,WAAW,EAAE;QACf,MAAMC,OAAO,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,EAAEzC,UAAU,CAAC,GAAG,IAAI,CAAC,CAAC;QAChDC,OAAO,CAACC,GAAG,CAAC,eAAeqC,OAAO,kBAAkBvC,UAAU,GAAG,CAAC,IAAIqC,UAAU,GAAG,CAAC;QACpF,MAAM,IAAI,CAAC5C,KAAK,CAAC8C,OAAO,CAAC;QACzB,OAAO,IAAI,CAACzC,WAAW,CAACC,QAAQ,EAAEC,UAAU,GAAG,CAAC,CAAC;MACnD;MAEA,IAAIM,KAAK,CAAC8B,IAAI,KAAK,cAAc,EAAE;QACjC,MAAM,IAAIvB,KAAK,CAAC,sCAAsC,CAAC;MACzD;MAEA,MAAM,IAAIA,KAAK,CAAC,EAAAmB,gBAAA,GAAA1B,KAAK,CAACY,QAAQ,cAAAc,gBAAA,wBAAAC,qBAAA,GAAdD,gBAAA,CAAgBT,IAAI,cAAAU,qBAAA,wBAAAC,sBAAA,GAApBD,qBAAA,CAAsB3B,KAAK,cAAA4B,sBAAA,uBAA3BA,sBAAA,CAA6BT,OAAO,KAAInB,KAAK,CAACmB,OAAO,IAAI,6BAA6B,CAAC;IACzG;EACF;EAEA,MAAMiB,gBAAgBA,CAACC,OAAe,EAA4B;IAChE1C,OAAO,CAAC2C,IAAI,CAAC,0BAA0B,CAAC;IACxC3C,OAAO,CAACC,GAAG,CAAC,mCAAmC,EAAEyC,OAAO,CAAC;IAEzD,MAAME,YAAY,GAAG;AACzB;AACA,yHAAyH;IAErH,MAAMC,UAAU,GAAG,aAAaH,OAAO;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuCA,OAAO;AAC9C;AACA;AACA;AACA;AACA,4BAA4BA,OAAO;AACnC,6BAA6BA,OAAO;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;IAEpB,MAAM5C,QAAQ,GAAG,CACf;MAAEgD,IAAI,EAAE,QAAQ;MAAErB,OAAO,EAAEmB;IAAa,CAAC,EACzC;MAAEE,IAAI,EAAE,MAAM;MAAErB,OAAO,EAAEoB;IAAW,CAAC,CACtC;IAED,MAAM5B,QAAQ,GAAG,MAAM,IAAI,CAACpB,WAAW,CAACC,QAAQ,CAAC;IACjDE,OAAO,CAAC+C,OAAO,CAAC,0BAA0B,CAAC;IAC3C/C,OAAO,CAACC,GAAG,CAAC,uCAAuC,EAAEgB,QAAQ,CAACb,MAAM,CAAC;IAErE,IAAI;MACF,MAAM4C,YAAY,GAAGC,IAAI,CAACC,KAAK,CAACjC,QAAQ,CAAC;MACzCjB,OAAO,CAACC,GAAG,CAAC,mCAAmC,CAAC;MAChD,OAAO+C,YAAY;IACrB,CAAC,CAAC,OAAOG,UAAU,EAAE;MACnBnD,OAAO,CAAC+C,OAAO,CAAC,0BAA0B,CAAC;MAC3C/C,OAAO,CAACK,KAAK,CAAC,oCAAoC,EAAE8C,UAAU,CAAC;MAC/DnD,OAAO,CAACC,GAAG,CAAC,eAAe,EAAEgB,QAAQ,CAACd,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,KAAK,CAAC;MAChE,MAAMiD,SAAS,GAAGnC,QAAQ,CAACoC,KAAK,CAAC,aAAa,CAAC;MAC/C,IAAID,SAAS,EAAE;QACb,OAAOH,IAAI,CAACC,KAAK,CAACE,SAAS,CAAC,CAAC,CAAC,CAAC;MACjC;MACA,MAAM,IAAIxC,KAAK,CAAC,+BAA+B,CAAC;IAClD;EACF;EAEA,MAAM0C,YAAYA,CAACZ,OAAe,EAAEa,QAAa,EAAgB;IAC/DvD,OAAO,CAACC,GAAG,CAAC,oCAAoC,EAAEyC,OAAO,CAAC;IAC1D1C,OAAO,CAACC,GAAG,CAAC,gBAAgB,EAAEsD,QAAQ,CAAC;IAEvC,MAAMX,YAAY,GAAG;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D;;IAE3D;IACA,IAAIY,eAAe,GAAG,EAAE;IACxB,IAAID,QAAQ,EAAE;MACZ,IAAIA,QAAQ,CAACE,UAAU,EAAED,eAAe,IAAI,iBAAiBD,QAAQ,CAACE,UAAU,EAAE;MAClF,IAAIF,QAAQ,CAACG,QAAQ,EAAEF,eAAe,IAAI,eAAeD,QAAQ,CAACG,QAAQ,EAAE;MAC5E,IAAIH,QAAQ,CAACI,aAAa,EAAEH,eAAe,IAAI,aAAaI,KAAK,CAACC,OAAO,CAACN,QAAQ,CAACI,aAAa,CAAC,GAAGJ,QAAQ,CAACI,aAAa,CAACG,IAAI,CAAC,IAAI,CAAC,GAAGP,QAAQ,CAACI,aAAa,EAAE;MAChK,IAAIJ,QAAQ,CAACQ,UAAU,EAAEP,eAAe,IAAI,iBAAiBP,IAAI,CAACe,SAAS,CAACT,QAAQ,CAACQ,UAAU,CAAC,CAACE,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE;MAChH,IAAIV,QAAQ,CAACW,eAAe,EAAEV,eAAe,IAAI,uBAAuBP,IAAI,CAACe,SAAS,CAACT,QAAQ,CAACW,eAAe,CAAC,CAACD,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE;MAChI,IAAIV,QAAQ,CAACY,YAAY,EAAEX,eAAe,IAAI,mBAAmBI,KAAK,CAACC,OAAO,CAACN,QAAQ,CAACY,YAAY,CAAC,GAAGZ,QAAQ,CAACY,YAAY,CAACL,IAAI,CAAC,IAAI,CAAC,GAAGP,QAAQ,CAACY,YAAY,EAAE;IACpK;IAEA,IAAI,CAACX,eAAe,EAAE;MACpBA,eAAe,GAAGP,IAAI,CAACe,SAAS,CAACT,QAAQ,EAAE,IAAI,EAAE,CAAC,CAAC,CAACU,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC;IACpE;IAEA,MAAMpB,UAAU,GAAG,0DAA0DH,OAAO;AACxF;AACA,gBAAgBc,eAAe;AAC/B;AACA;AACA;AACA;AACA,6DAA6Dd,OAAO;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAYA,OAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F;IAE3F,MAAM5C,QAAQ,GAAG,CACf;MAAEgD,IAAI,EAAE,QAAQ;MAAErB,OAAO,EAAEmB;IAAa,CAAC,EACzC;MAAEE,IAAI,EAAE,MAAM;MAAErB,OAAO,EAAEoB;IAAW,CAAC,CACtC;IAED,MAAM5B,QAAQ,GAAG,MAAM,IAAI,CAACpB,WAAW,CAACC,QAAQ,CAAC;IAEjD,IAAI;MACFE,OAAO,CAACC,GAAG,CAAC,sBAAsB,EAAEgB,QAAQ,CAACb,MAAM,CAAC;MACpDJ,OAAO,CAACC,GAAG,CAAC,mBAAmB,EAAEgB,QAAQ,CAACd,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC;MAC5DH,OAAO,CAACC,GAAG,CAAC,4BAA4B,EAAEgB,QAAQ,CAACmD,UAAU,CAAC,GAAG,CAAC,CAAC;MACnEpE,OAAO,CAACC,GAAG,CAAC,8BAA8B,EAAEgB,QAAQ,CAACd,SAAS,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;;MAEzE;MACA,IAAIkE,UAAU,GAAGpD,QAAQ,CAACqD,IAAI,CAAC,CAAC;;MAEhC;MACA,MAAMC,cAAc,GAAGF,UAAU,CAAChB,KAAK,CAAC,qCAAqC,CAAC;MAC9E,IAAIkB,cAAc,EAAE;QAClBF,UAAU,GAAGE,cAAc,CAAC,CAAC,CAAC;MAChC;;MAEA;MACA,MAAMC,YAAY,GAAGA,CAACC,SAAiB,EAAEC,UAAmB,GAAG,KAAK,KAAa;QAC/E,MAAMC,OAAO,GAAGD,UAAU,GACtB,IAAIE,MAAM,CAAC,IAAIH,SAAS,6CAA6C,EAAE,GAAG,CAAC,GAC3E,IAAIG,MAAM,CAAC,IAAIH,SAAS,qBAAqB,EAAE,GAAG,CAAC;QACvD,MAAMpB,KAAK,GAAGgB,UAAU,CAAChB,KAAK,CAACsB,OAAO,CAAC;QACvC,IAAItB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,EAAE;UACrB,IAAIwB,KAAK,GAAGxB,KAAK,CAAC,CAAC,CAAC;UACpB;UACAwB,KAAK,GAAGA,KAAK,CAACC,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC,CAAC;UACpCD,KAAK,GAAGA,KAAK,CAACC,OAAO,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC,CAAC;UACtC,IAAI,CAACJ,UAAU,EAAE;YACfG,KAAK,GAAGA,KAAK,CAACC,OAAO,CAAC,WAAW,EAAE,GAAG,CAAC,CAACR,IAAI,CAAC,CAAC;UAChD;UACA,OAAOO,KAAK;QACd;QACA,OAAO,EAAE;MACX,CAAC;MAED,MAAME,YAAY,GAAIN,SAAiB,IAAe;QACpD,MAAME,OAAO,GAAG,IAAIC,MAAM,CAAC,IAAIH,SAAS,yBAAyB,EAAE,GAAG,CAAC;QACvE,MAAMpB,KAAK,GAAGgB,UAAU,CAAChB,KAAK,CAACsB,OAAO,CAAC;QACvC,IAAItB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,EAAE;UACrB,OAAOA,KAAK,CAAC,CAAC,CAAC,CACZ2B,KAAK,CAAC,GAAG,CAAC,CACVC,GAAG,CAACC,CAAC,IAAIA,CAAC,CAACZ,IAAI,CAAC,CAAC,CAACQ,OAAO,CAAC,cAAc,EAAE,EAAE,CAAC,CAAC,CAC9CrE,MAAM,CAACyE,CAAC,IAAIA,CAAC,CAAC;QACnB;QACA,OAAO,EAAE;MACX,CAAC;MAED,MAAMC,aAAa,GAAIV,SAAiB,IAAa;QACnD,MAAME,OAAO,GAAG,IAAIC,MAAM,CAAC,IAAIH,SAAS,kBAAkB,EAAE,GAAG,CAAC;QAChE,MAAMpB,KAAK,GAAGgB,UAAU,CAAChB,KAAK,CAACsB,OAAO,CAAC;QACvC,OAAOtB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,GAAG+B,QAAQ,CAAC/B,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;MACnD,CAAC;;MAED;MACA,MAAMgC,QAAQ,GAAG;QACfC,KAAK,EAAEd,YAAY,CAAC,OAAO,CAAC,IAAI,mBAAmB9B,OAAO,EAAE;QAC5D6C,eAAe,EAAEf,YAAY,CAAC,iBAAiB,CAAC,IAAI,6BAA6B9B,OAAO,sCAAsC;QAC9HjB,OAAO,EAAE+C,YAAY,CAAC,SAAS,EAAE,IAAI,CAAC,IAAI,KAAK9B,OAAO,uCAAuC;QAC7F8C,SAAS,EAAEL,aAAa,CAAC,WAAW,CAAC,IAAI,IAAI;QAC7CM,WAAW,EAAEN,aAAa,CAAC,aAAa,CAAC,IAAI,CAAC;QAC9CO,cAAc,EAAEX,YAAY,CAAC,gBAAgB,CAAC,CAAC3E,MAAM,GAAG,CAAC,GAAG2E,YAAY,CAAC,gBAAgB,CAAC,GAAG,CAACrC,OAAO,CAAC;QACtGiD,gBAAgB,EAAEnB,YAAY,CAAC,kBAAkB,CAAC,IAAI;MACxD,CAAC;;MAED;MACAa,QAAQ,CAAC5D,OAAO,GAAG4D,QAAQ,CAAC5D,OAAO,CAChCqD,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,SAAS,EAAE,MAAM,CAAC,CAAC;MAAA,CAC3BR,IAAI,CAAC,CAAC;;MAET;MACA,IAAI,CAACe,QAAQ,CAAC5D,OAAO,CAACmE,QAAQ,CAAC,GAAG,CAAC,EAAE;QACnCP,QAAQ,CAAC5D,OAAO,GAAG,KAAK4D,QAAQ,CAACC,KAAK,OAAOD,QAAQ,CAAC5D,OAAO,EAAE;MACjE;MAEAzB,OAAO,CAACC,GAAG,CAAC,oCAAoC,CAAC;MACjD,OAAOoF,QAAQ;IACjB,CAAC,CAAC,OAAOlC,UAAe,EAAE;MAAA,IAAA0C,qBAAA;MACxB7F,OAAO,CAACK,KAAK,CAAC,gCAAgC,EAAE8C,UAAU,CAAC;MAC3DnD,OAAO,CAACK,KAAK,CAAC,sBAAsB,EAAE;QACpCmB,OAAO,EAAE2B,UAAU,CAAC3B,OAAO;QAC3BsE,QAAQ,GAAAD,qBAAA,GAAE1C,UAAU,CAAC3B,OAAO,CAAC6B,KAAK,CAAC,gBAAgB,CAAC,cAAAwC,qBAAA,uBAA1CA,qBAAA,CAA6C,CAAC,CAAC;QACzD5E,QAAQ,EAAEA,QAAQ,CAACd,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG;MACzC,CAAC,CAAC;;MAEF;MACA,MAAMiD,SAAS,GAAGnC,QAAQ,CAACoC,KAAK,CAAC,aAAa,CAAC;MAC/C,IAAID,SAAS,EAAE;QACb,IAAI;UACF,IAAI2C,cAAc,GAAG3C,SAAS,CAAC,CAAC,CAAC;;UAEjC;UACA2C,cAAc,GAAGA,cAAc,CAACjB,OAAO,CAAC,iDAAiD,EAAE,CAACzB,KAAK,EAAE5B,OAAO,KAAK;YAC7G,IAAIuE,KAAK,GAAGvE,OAAO;YACnBuE,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,KAAK,EAAE,MAAM,CAAC;YACpCkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,WAAW,EAAE,OAAO,CAAC;YAC3CkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,KAAK,EAAE,KAAK,CAAC;YACnCkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,YAAY,EAAE,OAAO,CAAC;YAC5CkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,MAAM,EAAE,KAAK,CAAC;YACpCkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,YAAY,EAAE,OAAO,CAAC;YAC5CkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,MAAM,EAAE,KAAK,CAAC;YACpCkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,YAAY,EAAE,OAAO,CAAC;YAC5CkB,KAAK,GAAGA,KAAK,CAAClB,OAAO,CAAC,MAAM,EAAE,KAAK,CAAC;YACpC,OAAO,eAAekB,KAAK,GAAG;UAChC,CAAC,CAAC;;UAEF;UACAD,cAAc,GAAGA,cAAc,CAACjB,OAAO,CAAC,2DAA2D,EAAE,CAACzB,KAAK,EAAE4C,KAAK,EAAExE,OAAO,KAAK;YAC9H,MAAMuE,KAAK,GAAGvE,OAAO,CAACqD,OAAO,CAAC,WAAW,EAAE,GAAG,CAAC,CAACR,IAAI,CAAC,CAAC;YACtD,OAAO,IAAI2B,KAAK,OAAOD,KAAK,GAAG;UACjC,CAAC,CAAC;;UAEF;UACAD,cAAc,GAAGA,cAAc,CAACjB,OAAO,CAAC,cAAc,EAAE,IAAI,CAAC;UAC7DiB,cAAc,GAAGA,cAAc,CAACjB,OAAO,CAAC,mCAAmC,EAAE,EAAE,CAAC;UAEhF,MAAMoB,SAAS,GAAGjD,IAAI,CAACC,KAAK,CAAC6C,cAAc,CAAC;UAC5C,IAAI,CAACG,SAAS,CAACV,SAAS,EAAEU,SAAS,CAACV,SAAS,GAAG,IAAI;UACpD,IAAI,CAACU,SAAS,CAACT,WAAW,EAAES,SAAS,CAACT,WAAW,GAAG,CAAC;UACrD,IAAI,CAACS,SAAS,CAACR,cAAc,EAAEQ,SAAS,CAACR,cAAc,GAAG,CAAChD,OAAO,CAAC;UACnE,IAAI,CAACwD,SAAS,CAACP,gBAAgB,EAAEO,SAAS,CAACP,gBAAgB,GAAG,SAAS;UACvE,OAAOO,SAAS;QAClB,CAAC,CAAC,OAAOC,CAAC,EAAE;UACVnG,OAAO,CAACK,KAAK,CAAC,iCAAiC,EAAE8F,CAAC,CAAC;QACrD;MACF;MACA,MAAM,IAAIvF,KAAK,CAAC,6BAA6B,GAAGuC,UAAU,CAAC3B,OAAO,CAAC;IACrE;EACF;AACF;AAEA,OAAO,MAAM4E,iBAAiB,GAAG,IAAI7G,iBAAiB,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}