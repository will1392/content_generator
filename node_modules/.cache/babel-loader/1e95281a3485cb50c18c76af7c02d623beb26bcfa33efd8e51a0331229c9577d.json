{"ast":null,"code":"// services/ai/perplexity.service.ts\nimport axios from 'axios';\nconst PERPLEXITY_API_URL = 'https://api.perplexity.ai/chat/completions';\n\n// Helper function to get API key dynamically\nconst getPerplexityApiKey = () => {\n  return process.env.REACT_APP_PERPLEXITY_API_KEY;\n};\nexport class PerplexityService {\n  async delay(ms) {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n  async makeRequest(messages, retryCount = 0) {\n    console.log('Making Perplexity API request...');\n    const apiKey = getPerplexityApiKey();\n    console.log('API Key exists:', !!apiKey);\n    console.log('API Key value:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined');\n    console.log('Messages length:', messages.length);\n    if (!apiKey) {\n      console.error('Environment variables:', {\n        REACT_APP_PERPLEXITY_API_KEY: process.env.REACT_APP_PERPLEXITY_API_KEY,\n        allEnvKeys: Object.keys(process.env).filter(key => key.startsWith('REACT_APP_'))\n      });\n      throw new Error('Perplexity API key is not configured. Please check your .env file.');\n    }\n    try {\n      const requestBody = {\n        model: 'sonar-pro',\n        messages,\n        temperature: 0.2,\n        max_tokens: 4000\n      };\n      console.log('Request body prepared, making API call...');\n      const response = await axios.post(PERPLEXITY_API_URL, requestBody, {\n        headers: {\n          'Authorization': `Bearer ${apiKey}`,\n          'Content-Type': 'application/json'\n        },\n        timeout: 120000 // 2 minute timeout\n      });\n      console.log('API response received, status:', response.status);\n      console.log('Response data structure:', Object.keys(response.data));\n      if (!response.data.choices || !response.data.choices[0]) {\n        throw new Error('Invalid API response structure');\n      }\n      return response.data.choices[0].message.content;\n    } catch (error) {\n      var _error$response, _error$response2, _error$response3, _error$response4, _error$response5, _error$response6, _error$response6$data, _error$response6$data2;\n      console.error('Perplexity API error details:', {\n        message: error.message,\n        response: (_error$response = error.response) === null || _error$response === void 0 ? void 0 : _error$response.data,\n        status: (_error$response2 = error.response) === null || _error$response2 === void 0 ? void 0 : _error$response2.status,\n        isTimeout: error.code === 'ECONNABORTED',\n        retryCount\n      });\n\n      // Retry logic for specific errors\n      const maxRetries = 2;\n      const shouldRetry = retryCount < maxRetries && (((_error$response3 = error.response) === null || _error$response3 === void 0 ? void 0 : _error$response3.status) === 429 ||\n      // Rate limit\n      ((_error$response4 = error.response) === null || _error$response4 === void 0 ? void 0 : _error$response4.status) === 503 ||\n      // Service unavailable\n      ((_error$response5 = error.response) === null || _error$response5 === void 0 ? void 0 : _error$response5.status) === 504 ||\n      // Gateway timeout\n      error.code === 'ECONNABORTED' ||\n      // Request timeout\n      error.code === 'ENOTFOUND' ||\n      // DNS issues\n      error.code === 'ECONNREFUSED' // Connection refused\n      );\n      if (shouldRetry) {\n        const delayMs = Math.pow(2, retryCount) * 1000; // Exponential backoff: 1s, 2s\n        console.log(`Retrying in ${delayMs}ms... (attempt ${retryCount + 1}/${maxRetries})`);\n        await this.delay(delayMs);\n        return this.makeRequest(messages, retryCount + 1);\n      }\n      if (error.code === 'ECONNABORTED') {\n        throw new Error('Request timed out - please try again');\n      }\n      throw new Error(((_error$response6 = error.response) === null || _error$response6 === void 0 ? void 0 : (_error$response6$data = _error$response6.data) === null || _error$response6$data === void 0 ? void 0 : (_error$response6$data2 = _error$response6$data.error) === null || _error$response6$data2 === void 0 ? void 0 : _error$response6$data2.message) || error.message || 'Failed to get research data');\n    }\n  }\n  async generateResearch(keyword) {\n    console.time('Perplexity Research Time');\n    console.log('Starting Perplexity research for:', keyword);\n    const systemPrompt = `You are an expert SEO research analyst focused on E-E-A-T (Experience, Expertise, Authoritativeness, Trustworthiness). \n    Your research will be used to create content that ranks well on Google by demonstrating real expertise and authority.\n    Always provide specific, verifiable data with sources. Focus on unique insights that demonstrate deep understanding.`;\n    const userPrompt = `Research \"${keyword}\" and provide comprehensive information in JSON format.\n\nInclude:\n1. Definition and overview\n2. Current trends and statistics\n3. Common questions people ask\n4. Related topics and applications\n5. Key challenges and opportunities\n\nFormat as JSON:\n{\n  \"definition\": \"Clear definition of ${keyword}\",\n  \"overview\": \"Comprehensive overview\",\n  \"currentTrends\": [\"trend1\", \"trend2\", \"trend3\"],\n  \"statistics\": [\"stat1 with source\", \"stat2 with source\"],\n  \"commonQuestions\": [\n    {\"question\": \"What is ${keyword}?\", \"answer\": \"detailed answer\"},\n    {\"question\": \"How does ${keyword} work?\", \"answer\": \"detailed answer\"}\n  ],\n  \"relatedTopics\": [\"topic1\", \"topic2\", \"topic3\"],\n  \"applications\": [\"application1\", \"application2\"],\n  \"challenges\": [\"challenge1\", \"challenge2\"],\n  \"opportunities\": [\"opportunity1\", \"opportunity2\"],\n  \"futureOutlook\": \"Analysis of future trends\"\n}\n\nReturn only valid JSON.`;\n    const messages = [{\n      role: 'system',\n      content: systemPrompt\n    }, {\n      role: 'user',\n      content: userPrompt\n    }];\n    const response = await this.makeRequest(messages);\n    console.timeEnd('Perplexity Research Time');\n    console.log('Perplexity response received, length:', response.length);\n    try {\n      const researchData = JSON.parse(response);\n      console.log('Research data parsed successfully');\n      return researchData;\n    } catch (parseError) {\n      console.timeEnd('Perplexity Research Time');\n      console.error('Failed to parse research response:', parseError);\n      console.log('Raw response:', response.substring(0, 500) + '...');\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        return JSON.parse(jsonMatch[0]);\n      }\n      throw new Error('Failed to parse research data');\n    }\n  }\n  async generatePodcastScript(keyword, research, blog) {\n    var _blog$content;\n    console.log('Generating podcast script for:', keyword);\n    console.log('Blog content length:', (blog === null || blog === void 0 ? void 0 : (_blog$content = blog.content) === null || _blog$content === void 0 ? void 0 : _blog$content.length) || 0);\n    console.log('Research keys:', research ? Object.keys(research) : 'No research');\n    const systemPrompt = `You are generating a podcast episode featuring two hosts: Alex and Jordan. They are knowledgeable, engaging, and bring different personalities to the show. Alex is more analytical and structured, while Jordan is more casual and prone to storytelling or going off on rants.\n\nYou specialize in creating natural, unscripted-feeling conversations that mimic real podcast dynamics. Your scripts avoid robotic delivery and include authentic banter, reactions, and personality-driven moments.`;\n\n    // Extract key points from the blog content\n    const blogSummary = blog !== null && blog !== void 0 && blog.content ? blog.content.substring(0, 2000) : '';\n\n    // Build research insights\n    let researchInsights = '';\n    if (research) {\n      if (research.definition) researchInsights += `\\nKey Definition: ${research.definition}`;\n      if (research.currentTrends) researchInsights += `\\nTrends: ${Array.isArray(research.currentTrends) ? research.currentTrends.join(', ') : research.currentTrends}`;\n      if (research.statistics && Array.isArray(research.statistics)) {\n        researchInsights += `\\nStatistics: ${research.statistics.slice(0, 3).map(stat => typeof stat === 'object' ? `${stat.metric}: ${stat.value}` : stat).join(', ')}`;\n      }\n      if (research.applications) researchInsights += `\\nApplications: ${Array.isArray(research.applications) ? research.applications.join(', ') : research.applications}`;\n    }\n    const userPrompt = `Create an engaging podcast script about \"${keyword}\" based on the provided blog content and research.\n\nBLOG CONTENT SUMMARY:\n${blogSummary}\n\nRESEARCH INSIGHTS:${researchInsights}\n\nThe topic of the podcast is: \"${keyword}\". This episode is based on a blog post that covers this topic in-depth, but the goal is to make the discussion feel unscripted, natural, and authentic.\n\nTONE & STYLE GUIDELINES:\n- Mimic real podcast dynamics\n- Do NOT simply alternate back and forth after every paragraph\n- Sometimes let one host talk for a longer stretch if it fits their character (especially Jordan for rants or stories)\n- Include casual banter, inside jokes, laughter, or clarifying questions\n- Occasionally include light disagreement or friendly teasing to sound natural\n- Avoid robotic delivery or stiff transitions\n\nSTRUCTURE OF THE EPISODE:\n\n1. **Introduction (1-2 minutes)**\n   - Hosts greet each other\n   - Brief summary of what the episode is about\n   - Light banter to establish rapport\n\n2. **Main Discussion**\n   - Cover key points of the topic (based on the blog)\n   - Add commentary, real-world examples, or personal anecdotes\n   - Let Jordan occasionally go on a humorous or passionate rant\n   - Alex can jump in with clarification, stats, or counterpoints\n\n3. **Segment Transitions**\n   - Use natural transitions like: \"Before we move on...\", \"This reminds me of...\", \"Let's talk about something related...\"\n\n4. **Closing Thoughts**\n   - Final reflections from each host\n   - Quick summary or takeaway\n   - Mention of what's coming next or CTA (optional)\n\nADDITIONAL BEHAVIORS TO SIMULATE:\n- Pauses or filler phrases like \"you know,\" \"honestly,\" \"that's wild\"\n- Reactions like \"wow,\" \"no way,\" \"I didn't know that!\"\n- Quick recaps when going off-topic before returning to the main point\n- A few ad-libbed examples that aren't in the blog but feel relevant\n\nFORMATTING:\nOutput as a script with speaker names, like:\n\nAlex: Hey everyone, welcome back to the pod. Today we're diving into something pretty fascinating...\n\nJordan: Yeah, and I've got *thoughts* on this one—like, big thoughts.\n\nFORMAT YOUR RESPONSE AS JSON:\n{\n  \"title\": \"Natural podcast episode title with keyword\",\n  \"script\": \"Full two-host podcast script with Alex and Jordan as speakers, natural conversations, banter, and authentic dynamics\",\n  \"duration\": 18,\n  \"outline\": [\n    \"Introduction and banter\",\n    \"Topic overview with host reactions\", \n    \"Deep dive with Jordan rants\",\n    \"Alex analysis and counterpoints\", \n    \"Real-world examples and stories\",\n    \"Closing thoughts and takeaways\"\n  ]\n}\n\nCreate a script that feels like two real friends having an authentic conversation about ${keyword}, not a formal presentation.`;\n    const messages = [{\n      role: 'system',\n      content: systemPrompt\n    }, {\n      role: 'user',\n      content: userPrompt\n    }];\n    const response = await this.makeRequest(messages);\n    try {\n      console.log('Raw podcast response length:', response.length);\n      console.log('Response preview:', response.substring(0, 300));\n\n      // Try to parse the response\n      let jsonString = response.trim();\n\n      // If the response has markdown code blocks, extract the JSON from them\n      const codeBlockMatch = jsonString.match(/```(?:json)?\\s*(\\{[\\s\\S]*?\\})\\s*```/);\n      if (codeBlockMatch) {\n        jsonString = codeBlockMatch[1];\n      }\n\n      // Extract fields using regex for more robust parsing\n      const extractField = (fieldName, isLongText = false) => {\n        const pattern = isLongText ? new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([\\\\s\\\\S]*?)(?=\",\\\\s*\"|\"\\\\s*}|$)`, 'i') : new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([^\"]*)\"`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          let value = match[1];\n          // Clean up the extracted value\n          value = value.replace(/\\\\\"/g, '\"'); // Unescape quotes\n          value = value.replace(/\\\\\\\\/g, '\\\\'); // Unescape backslashes\n          if (!isLongText) {\n            value = value.replace(/[\\n\\r\\t]/g, ' ').trim();\n          }\n          return value;\n        }\n        return '';\n      };\n      const extractArray = fieldName => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\\\\[([^\\\\]]*)]`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          return match[1].split(',').map(s => s.trim().replace(/^[\"']|[\"']$/g, '')).filter(s => s);\n        }\n        return [];\n      };\n      const extractNumber = fieldName => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*(\\\\d+)`, 'i');\n        const match = jsonString.match(pattern);\n        return match && match[1] ? parseInt(match[1]) : 18;\n      };\n\n      // Manually construct the podcast data object\n      const podcastData = {\n        title: extractField('title') || `${keyword} Podcast Episode`,\n        script: extractField('script', true) || `# ${keyword} Podcast Script\\n\\nWelcome to today's episode about ${keyword}...`,\n        duration: extractNumber('duration') || 18,\n        outline: extractArray('outline').length > 0 ? extractArray('outline') : [\"Introduction and hook\", \"Main topic overview\", \"Key insights\", \"Conclusion and takeaways\"]\n      };\n\n      // Clean the script field\n      podcastData.script = podcastData.script.replace(/\\\\n/g, '\\n').replace(/\\\\r/g, '\\r').replace(/\\\\t/g, '\\t').replace(/\\n{3,}/g, '\\n\\n').trim();\n      console.log('Successfully constructed podcast data');\n      return podcastData;\n    } catch (parseError) {\n      console.error('Failed to parse podcast response:', parseError);\n\n      // Fallback: create basic structure from response\n      console.log('Using fallback podcast structure');\n      return {\n        title: `${keyword} Podcast Episode`,\n        script: response,\n        duration: 18,\n        outline: [\"Introduction\", \"Main discussion\", \"Key insights\", \"Conclusion\"]\n      };\n    }\n  }\n  async generateBlog(keyword, research) {\n    console.log('Generating SEO-optimized blog for:', keyword);\n    console.log('Research data:', research);\n    const systemPrompt = `You are an expert SEO content writer who creates highly engaging, authoritative content that ranks well on Google. \n    You follow E-E-A-T principles and write content that demonstrates real expertise, experience, authority, and trustworthiness.\n    Your content is comprehensive, well-structured, and naturally incorporates keywords for optimal SEO performance.\n    \n    IMPORTANT: Write at an 8th-grade reading level using:\n    - Short sentences (15-20 words max)\n    - Simple, common words\n    - Active voice\n    - Clear, direct language\n    - One idea per sentence\n    - Avoid jargon unless necessary (and explain it when used)`;\n\n    // Build research summary from available data\n    let researchSummary = '';\n    if (research) {\n      if (research.definition) researchSummary += `\\nDefinition: ${research.definition}`;\n      if (research.overview) researchSummary += `\\nOverview: ${research.overview}`;\n      if (research.currentTrends) researchSummary += `\\nTrends: ${Array.isArray(research.currentTrends) ? research.currentTrends.join(', ') : research.currentTrends}`;\n      if (research.statistics) researchSummary += `\\nStatistics: ${JSON.stringify(research.statistics).slice(0, 500)}`;\n      if (research.commonQuestions) researchSummary += `\\nCommon Questions: ${JSON.stringify(research.commonQuestions).slice(0, 500)}`;\n      if (research.applications) researchSummary += `\\nApplications: ${Array.isArray(research.applications) ? research.applications.join(', ') : research.applications}`;\n    }\n    if (!researchSummary) {\n      researchSummary = JSON.stringify(research, null, 2).slice(0, 2000);\n    }\n    const userPrompt = `Create a comprehensive, SEO-optimized blog post about \"${keyword}\" using the provided research data.\n\nRESEARCH DATA:${researchSummary}\n\nBLOG POST REQUIREMENTS:\n\n1. Create a blog post that is 1,500-2,000 words long\n2. Include an SEO-optimized title that naturally includes \"${keyword}\"\n3. Write a compelling meta description (155-160 characters)\n4. Structure with:\n   - Engaging introduction with a hook\n   - 5-7 main sections with H2 headings\n   - Subsections with H3 headings where appropriate\n   - Conclusion with clear call-to-action\n\n5. SEO Optimization:\n   - Use \"${keyword}\" naturally 5-7 times throughout\n   - Include semantic variations and related terms\n   - Target potential featured snippets with clear, concise answers\n   - Write in an easy-to-read style (8th-grade level)\n\n6. READABILITY REQUIREMENTS (8th Grade Level):\n   - Use short sentences (15-20 words maximum)\n   - Choose simple, everyday words over complex ones\n   - Write in active voice (\"We tested\" not \"It was tested\")\n   - Break complex ideas into simple steps\n   - Use transition words (First, Next, However, Therefore)\n   - Define technical terms in simple language\n   - Use concrete examples to explain abstract concepts\n\n7. Demonstrate E-E-A-T:\n   - Show expertise through accurate information\n   - Include statistics and data points from the research\n   - Reference authoritative sources\n   - Provide practical, actionable advice\n\n8. Engagement:\n   - Use short paragraphs (2-3 sentences)\n   - Include bullet points and lists\n   - Add examples and analogies\n   - Keep the tone conversational but professional\n   - Ask rhetorical questions to engage readers\n   - Use \"you\" to speak directly to the reader\n\nFORMAT YOUR RESPONSE AS JSON:\n{\n  \"title\": \"SEO-optimized title with keyword\",\n  \"metaDescription\": \"Compelling meta description 155-160 characters with keyword\",\n  \"content\": \"Full blog post in Markdown format with ## for H2 and ### for H3 headings\",\n  \"wordCount\": 1800,\n  \"readingTime\": 8,\n  \"targetKeywords\": [\"main keyword\", \"related keyword 1\", \"related keyword 2\"],\n  \"readabilityScore\": \"Grade 8\"\n}\n\nRemember: Write clearly and simply. If a 13-year-old can understand it, you're doing it right.`;\n    const messages = [{\n      role: 'system',\n      content: systemPrompt\n    }, {\n      role: 'user',\n      content: userPrompt\n    }];\n    const response = await this.makeRequest(messages);\n    try {\n      console.log('Raw response length:', response.length);\n      console.log('Response preview:', response.substring(0, 500));\n      console.log('Character at position 509:', response.charCodeAt(509));\n      console.log('Context around position 509:', response.substring(500, 520));\n\n      // Try a more aggressive approach - parse the response structure manually\n      let jsonString = response.trim();\n\n      // If the response has markdown code blocks, extract the JSON from them\n      const codeBlockMatch = jsonString.match(/```(?:json)?\\s*(\\{[\\s\\S]*?\\})\\s*```/);\n      if (codeBlockMatch) {\n        jsonString = codeBlockMatch[1];\n      }\n\n      // Extract fields using regex instead of trying to parse potentially broken JSON\n      const extractField = (fieldName, isLongText = false) => {\n        const pattern = isLongText ? new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([\\\\s\\\\S]*?)(?=\",\\\\s*\"|\"\\\\s*}|$)`, 'i') : new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([^\"]*)\"`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          let value = match[1];\n          // Clean up the extracted value\n          value = value.replace(/\\\\\"/g, '\"'); // Unescape quotes\n          value = value.replace(/\\\\\\\\/g, '\\\\'); // Unescape backslashes\n          if (!isLongText) {\n            value = value.replace(/[\\n\\r\\t]/g, ' ').trim();\n          }\n          return value;\n        }\n        return '';\n      };\n      const extractArray = fieldName => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\\\\[([^\\\\]]*)]`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          return match[1].split(',').map(s => s.trim().replace(/^[\"']|[\"']$/g, '')).filter(s => s);\n        }\n        return [];\n      };\n      const extractNumber = fieldName => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*(\\\\d+)`, 'i');\n        const match = jsonString.match(pattern);\n        return match && match[1] ? parseInt(match[1]) : 0;\n      };\n\n      // Manually construct the blog data object\n      const blogData = {\n        title: extractField('title') || `Expert Guide to ${keyword}`,\n        metaDescription: extractField('metaDescription') || `Comprehensive guide about ${keyword}. Learn everything you need to know.`,\n        content: extractField('content', true) || `# ${keyword}\\n\\nContent generation in progress...`,\n        wordCount: extractNumber('wordCount') || 1500,\n        readingTime: extractNumber('readingTime') || 8,\n        targetKeywords: extractArray('targetKeywords').length > 0 ? extractArray('targetKeywords') : [keyword],\n        readabilityScore: extractField('readabilityScore') || 'Grade 8'\n      };\n\n      // Clean the content field to ensure it's valid markdown\n      blogData.content = blogData.content.replace(/\\\\n/g, '\\n').replace(/\\\\r/g, '\\r').replace(/\\\\t/g, '\\t').replace(/\\n{3,}/g, '\\n\\n') // Limit consecutive newlines\n      .trim();\n\n      // Ensure content has proper markdown structure\n      if (!blogData.content.includes('#')) {\n        blogData.content = `# ${blogData.title}\\n\\n${blogData.content}`;\n      }\n      console.log('Successfully constructed blog data');\n      return blogData;\n    } catch (parseError) {\n      var _parseError$message$m;\n      console.error('Failed to parse blog response:', parseError);\n      console.error('Parse error details:', {\n        message: parseError.message,\n        position: (_parseError$message$m = parseError.message.match(/position (\\d+)/)) === null || _parseError$message$m === void 0 ? void 0 : _parseError$message$m[1],\n        response: response.substring(0, 600) + '...'\n      });\n\n      // Try to extract JSON from the response\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        try {\n          let cleanedExtract = jsonMatch[0];\n\n          // Apply the same cleaning logic as above\n          cleanedExtract = cleanedExtract.replace(/\"content\"\\s*:\\s*\"([\\s\\S]*?)\"\\s*(?=,\\s*\"|\\s*\\})/g, (match, content) => {\n            let fixed = content;\n            fixed = fixed.replace(/\\\\/g, '\\\\\\\\');\n            fixed = fixed.replace(/([^\\\\])\"/g, '$1\\\\\"');\n            fixed = fixed.replace(/^\"/g, '\\\\\"');\n            fixed = fixed.replace(/([^\\\\])\\n/g, '$1\\\\n');\n            fixed = fixed.replace(/^\\n/g, '\\\\n');\n            fixed = fixed.replace(/([^\\\\])\\r/g, '$1\\\\r');\n            fixed = fixed.replace(/^\\r/g, '\\\\r');\n            fixed = fixed.replace(/([^\\\\])\\t/g, '$1\\\\t');\n            fixed = fixed.replace(/^\\t/g, '\\\\t');\n            return `\"content\": \"${fixed}\"`;\n          });\n\n          // Clean other fields\n          cleanedExtract = cleanedExtract.replace(/\"(title|metaDescription)\"\\s*:\\s*\"([^\"\\\\]*(\\\\.[^\"\\\\]*)*)\"/g, (match, field, content) => {\n            const fixed = content.replace(/[\\n\\r\\t]/g, ' ').trim();\n            return `\"${field}\": \"${fixed}\"`;\n          });\n\n          // Remove trailing commas and control characters\n          cleanedExtract = cleanedExtract.replace(/,\\s*([}\\]])/g, '$1');\n          cleanedExtract = cleanedExtract.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g, '');\n          const extracted = JSON.parse(cleanedExtract);\n          if (!extracted.wordCount) extracted.wordCount = 1500;\n          if (!extracted.readingTime) extracted.readingTime = 8;\n          if (!extracted.targetKeywords) extracted.targetKeywords = [keyword];\n          if (!extracted.readabilityScore) extracted.readabilityScore = \"Grade 8\";\n          return extracted;\n        } catch (e) {\n          console.error('Failed to parse extracted JSON:', e);\n        }\n      }\n      throw new Error('Failed to parse blog data: ' + parseError.message);\n    }\n  }\n}\nexport const perplexityService = new PerplexityService();","map":{"version":3,"names":["axios","PERPLEXITY_API_URL","getPerplexityApiKey","process","env","REACT_APP_PERPLEXITY_API_KEY","PerplexityService","delay","ms","Promise","resolve","setTimeout","makeRequest","messages","retryCount","console","log","apiKey","substring","length","error","allEnvKeys","Object","keys","filter","key","startsWith","Error","requestBody","model","temperature","max_tokens","response","post","headers","timeout","status","data","choices","message","content","_error$response","_error$response2","_error$response3","_error$response4","_error$response5","_error$response6","_error$response6$data","_error$response6$data2","isTimeout","code","maxRetries","shouldRetry","delayMs","Math","pow","generateResearch","keyword","time","systemPrompt","userPrompt","role","timeEnd","researchData","JSON","parse","parseError","jsonMatch","match","generatePodcastScript","research","blog","_blog$content","blogSummary","researchInsights","definition","currentTrends","Array","isArray","join","statistics","slice","map","stat","metric","value","applications","jsonString","trim","codeBlockMatch","extractField","fieldName","isLongText","pattern","RegExp","replace","extractArray","split","s","extractNumber","parseInt","podcastData","title","script","duration","outline","generateBlog","researchSummary","overview","stringify","commonQuestions","charCodeAt","blogData","metaDescription","wordCount","readingTime","targetKeywords","readabilityScore","includes","_parseError$message$m","position","cleanedExtract","fixed","field","extracted","e","perplexityService"],"sources":["/Users/will/Content Creation App/src/services/ai/perplexity.service.ts"],"sourcesContent":["// services/ai/perplexity.service.ts\nimport axios from 'axios';\nimport { ResearchContent } from '../../types/project.types';\n\nconst PERPLEXITY_API_URL = 'https://api.perplexity.ai/chat/completions';\n\n// Helper function to get API key dynamically\nconst getPerplexityApiKey = () => {\n  return process.env.REACT_APP_PERPLEXITY_API_KEY;\n};\n\ninterface PerplexityResponse {\n  id: string;\n  model: string;\n  choices: Array<{\n    message: {\n      role: string;\n      content: string;\n    };\n    finish_reason: string;\n  }>;\n}\n\nexport class PerplexityService {\n  private async delay(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n\n  private async makeRequest(messages: any[], retryCount: number = 0): Promise<string> {\n    console.log('Making Perplexity API request...');\n    const apiKey = getPerplexityApiKey();\n    console.log('API Key exists:', !!apiKey);\n    console.log('API Key value:', apiKey ? `${apiKey.substring(0, 10)}...` : 'undefined');\n    console.log('Messages length:', messages.length);\n    \n    if (!apiKey) {\n      console.error('Environment variables:', {\n        REACT_APP_PERPLEXITY_API_KEY: process.env.REACT_APP_PERPLEXITY_API_KEY,\n        allEnvKeys: Object.keys(process.env).filter(key => key.startsWith('REACT_APP_'))\n      });\n      throw new Error('Perplexity API key is not configured. Please check your .env file.');\n    }\n    \n    try {\n      const requestBody = {\n        model: 'sonar-pro',\n        messages,\n        temperature: 0.2,\n        max_tokens: 4000,\n      };\n      \n      console.log('Request body prepared, making API call...');\n      \n      const response = await axios.post<PerplexityResponse>(\n        PERPLEXITY_API_URL,\n        requestBody,\n        {\n          headers: {\n            'Authorization': `Bearer ${apiKey}`,\n            'Content-Type': 'application/json',\n          },\n          timeout: 120000, // 2 minute timeout\n        }\n      );\n\n      console.log('API response received, status:', response.status);\n      console.log('Response data structure:', Object.keys(response.data));\n      \n      if (!response.data.choices || !response.data.choices[0]) {\n        throw new Error('Invalid API response structure');\n      }\n\n      return response.data.choices[0].message.content;\n    } catch (error: any) {\n      console.error('Perplexity API error details:', {\n        message: error.message,\n        response: error.response?.data,\n        status: error.response?.status,\n        isTimeout: error.code === 'ECONNABORTED',\n        retryCount\n      });\n      \n      // Retry logic for specific errors\n      const maxRetries = 2;\n      const shouldRetry = retryCount < maxRetries && (\n        error.response?.status === 429 || // Rate limit\n        error.response?.status === 503 || // Service unavailable\n        error.response?.status === 504 || // Gateway timeout\n        error.code === 'ECONNABORTED' ||  // Request timeout\n        error.code === 'ENOTFOUND' ||      // DNS issues\n        error.code === 'ECONNREFUSED'      // Connection refused\n      );\n      \n      if (shouldRetry) {\n        const delayMs = Math.pow(2, retryCount) * 1000; // Exponential backoff: 1s, 2s\n        console.log(`Retrying in ${delayMs}ms... (attempt ${retryCount + 1}/${maxRetries})`);\n        await this.delay(delayMs);\n        return this.makeRequest(messages, retryCount + 1);\n      }\n      \n      if (error.code === 'ECONNABORTED') {\n        throw new Error('Request timed out - please try again');\n      }\n      \n      throw new Error(error.response?.data?.error?.message || error.message || 'Failed to get research data');\n    }\n  }\n\n  async generateResearch(keyword: string): Promise<ResearchContent> {\n    console.time('Perplexity Research Time');\n    console.log('Starting Perplexity research for:', keyword);\n    \n    const systemPrompt = `You are an expert SEO research analyst focused on E-E-A-T (Experience, Expertise, Authoritativeness, Trustworthiness). \n    Your research will be used to create content that ranks well on Google by demonstrating real expertise and authority.\n    Always provide specific, verifiable data with sources. Focus on unique insights that demonstrate deep understanding.`;\n\n    const userPrompt = `Research \"${keyword}\" and provide comprehensive information in JSON format.\n\nInclude:\n1. Definition and overview\n2. Current trends and statistics\n3. Common questions people ask\n4. Related topics and applications\n5. Key challenges and opportunities\n\nFormat as JSON:\n{\n  \"definition\": \"Clear definition of ${keyword}\",\n  \"overview\": \"Comprehensive overview\",\n  \"currentTrends\": [\"trend1\", \"trend2\", \"trend3\"],\n  \"statistics\": [\"stat1 with source\", \"stat2 with source\"],\n  \"commonQuestions\": [\n    {\"question\": \"What is ${keyword}?\", \"answer\": \"detailed answer\"},\n    {\"question\": \"How does ${keyword} work?\", \"answer\": \"detailed answer\"}\n  ],\n  \"relatedTopics\": [\"topic1\", \"topic2\", \"topic3\"],\n  \"applications\": [\"application1\", \"application2\"],\n  \"challenges\": [\"challenge1\", \"challenge2\"],\n  \"opportunities\": [\"opportunity1\", \"opportunity2\"],\n  \"futureOutlook\": \"Analysis of future trends\"\n}\n\nReturn only valid JSON.`;\n\n    const messages = [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: userPrompt }\n    ];\n\n    const response = await this.makeRequest(messages);\n    console.timeEnd('Perplexity Research Time');\n    console.log('Perplexity response received, length:', response.length);\n    \n    try {\n      const researchData = JSON.parse(response);\n      console.log('Research data parsed successfully');\n      return researchData as ResearchContent;\n    } catch (parseError) {\n      console.timeEnd('Perplexity Research Time');\n      console.error('Failed to parse research response:', parseError);\n      console.log('Raw response:', response.substring(0, 500) + '...');\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        return JSON.parse(jsonMatch[0]) as ResearchContent;\n      }\n      throw new Error('Failed to parse research data');\n    }\n  }\n\n  async generatePodcastScript(keyword: string, research: any, blog: any): Promise<any> {\n    console.log('Generating podcast script for:', keyword);\n    console.log('Blog content length:', blog?.content?.length || 0);\n    console.log('Research keys:', research ? Object.keys(research) : 'No research');\n\n    const systemPrompt = `You are generating a podcast episode featuring two hosts: Alex and Jordan. They are knowledgeable, engaging, and bring different personalities to the show. Alex is more analytical and structured, while Jordan is more casual and prone to storytelling or going off on rants.\n\nYou specialize in creating natural, unscripted-feeling conversations that mimic real podcast dynamics. Your scripts avoid robotic delivery and include authentic banter, reactions, and personality-driven moments.`;\n\n    // Extract key points from the blog content\n    const blogSummary = blog?.content ? blog.content.substring(0, 2000) : '';\n    \n    // Build research insights\n    let researchInsights = '';\n    if (research) {\n      if (research.definition) researchInsights += `\\nKey Definition: ${research.definition}`;\n      if (research.currentTrends) researchInsights += `\\nTrends: ${Array.isArray(research.currentTrends) ? research.currentTrends.join(', ') : research.currentTrends}`;\n      if (research.statistics && Array.isArray(research.statistics)) {\n        researchInsights += `\\nStatistics: ${research.statistics.slice(0, 3).map((stat: any) => \n          typeof stat === 'object' ? `${stat.metric}: ${stat.value}` : stat\n        ).join(', ')}`;\n      }\n      if (research.applications) researchInsights += `\\nApplications: ${Array.isArray(research.applications) ? research.applications.join(', ') : research.applications}`;\n    }\n\n    const userPrompt = `Create an engaging podcast script about \"${keyword}\" based on the provided blog content and research.\n\nBLOG CONTENT SUMMARY:\n${blogSummary}\n\nRESEARCH INSIGHTS:${researchInsights}\n\nThe topic of the podcast is: \"${keyword}\". This episode is based on a blog post that covers this topic in-depth, but the goal is to make the discussion feel unscripted, natural, and authentic.\n\nTONE & STYLE GUIDELINES:\n- Mimic real podcast dynamics\n- Do NOT simply alternate back and forth after every paragraph\n- Sometimes let one host talk for a longer stretch if it fits their character (especially Jordan for rants or stories)\n- Include casual banter, inside jokes, laughter, or clarifying questions\n- Occasionally include light disagreement or friendly teasing to sound natural\n- Avoid robotic delivery or stiff transitions\n\nSTRUCTURE OF THE EPISODE:\n\n1. **Introduction (1-2 minutes)**\n   - Hosts greet each other\n   - Brief summary of what the episode is about\n   - Light banter to establish rapport\n\n2. **Main Discussion**\n   - Cover key points of the topic (based on the blog)\n   - Add commentary, real-world examples, or personal anecdotes\n   - Let Jordan occasionally go on a humorous or passionate rant\n   - Alex can jump in with clarification, stats, or counterpoints\n\n3. **Segment Transitions**\n   - Use natural transitions like: \"Before we move on...\", \"This reminds me of...\", \"Let's talk about something related...\"\n\n4. **Closing Thoughts**\n   - Final reflections from each host\n   - Quick summary or takeaway\n   - Mention of what's coming next or CTA (optional)\n\nADDITIONAL BEHAVIORS TO SIMULATE:\n- Pauses or filler phrases like \"you know,\" \"honestly,\" \"that's wild\"\n- Reactions like \"wow,\" \"no way,\" \"I didn't know that!\"\n- Quick recaps when going off-topic before returning to the main point\n- A few ad-libbed examples that aren't in the blog but feel relevant\n\nFORMATTING:\nOutput as a script with speaker names, like:\n\nAlex: Hey everyone, welcome back to the pod. Today we're diving into something pretty fascinating...\n\nJordan: Yeah, and I've got *thoughts* on this one—like, big thoughts.\n\nFORMAT YOUR RESPONSE AS JSON:\n{\n  \"title\": \"Natural podcast episode title with keyword\",\n  \"script\": \"Full two-host podcast script with Alex and Jordan as speakers, natural conversations, banter, and authentic dynamics\",\n  \"duration\": 18,\n  \"outline\": [\n    \"Introduction and banter\",\n    \"Topic overview with host reactions\", \n    \"Deep dive with Jordan rants\",\n    \"Alex analysis and counterpoints\", \n    \"Real-world examples and stories\",\n    \"Closing thoughts and takeaways\"\n  ]\n}\n\nCreate a script that feels like two real friends having an authentic conversation about ${keyword}, not a formal presentation.`;\n\n    const messages = [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: userPrompt }\n    ];\n\n    const response = await this.makeRequest(messages);\n    \n    try {\n      console.log('Raw podcast response length:', response.length);\n      console.log('Response preview:', response.substring(0, 300));\n      \n      // Try to parse the response\n      let jsonString = response.trim();\n      \n      // If the response has markdown code blocks, extract the JSON from them\n      const codeBlockMatch = jsonString.match(/```(?:json)?\\s*(\\{[\\s\\S]*?\\})\\s*```/);\n      if (codeBlockMatch) {\n        jsonString = codeBlockMatch[1];\n      }\n      \n      // Extract fields using regex for more robust parsing\n      const extractField = (fieldName: string, isLongText: boolean = false): string => {\n        const pattern = isLongText \n          ? new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([\\\\s\\\\S]*?)(?=\",\\\\s*\"|\"\\\\s*}|$)`, 'i')\n          : new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([^\"]*)\"`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          let value = match[1];\n          // Clean up the extracted value\n          value = value.replace(/\\\\\"/g, '\"'); // Unescape quotes\n          value = value.replace(/\\\\\\\\/g, '\\\\'); // Unescape backslashes\n          if (!isLongText) {\n            value = value.replace(/[\\n\\r\\t]/g, ' ').trim();\n          }\n          return value;\n        }\n        return '';\n      };\n      \n      const extractArray = (fieldName: string): string[] => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\\\\[([^\\\\]]*)]`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          return match[1]\n            .split(',')\n            .map(s => s.trim().replace(/^[\"']|[\"']$/g, ''))\n            .filter(s => s);\n        }\n        return [];\n      };\n      \n      const extractNumber = (fieldName: string): number => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*(\\\\d+)`, 'i');\n        const match = jsonString.match(pattern);\n        return match && match[1] ? parseInt(match[1]) : 18;\n      };\n      \n      // Manually construct the podcast data object\n      const podcastData = {\n        title: extractField('title') || `${keyword} Podcast Episode`,\n        script: extractField('script', true) || `# ${keyword} Podcast Script\\n\\nWelcome to today's episode about ${keyword}...`,\n        duration: extractNumber('duration') || 18,\n        outline: extractArray('outline').length > 0 ? extractArray('outline') : [\n          \"Introduction and hook\",\n          \"Main topic overview\", \n          \"Key insights\",\n          \"Conclusion and takeaways\"\n        ]\n      };\n      \n      // Clean the script field\n      podcastData.script = podcastData.script\n        .replace(/\\\\n/g, '\\n')\n        .replace(/\\\\r/g, '\\r')\n        .replace(/\\\\t/g, '\\t')\n        .replace(/\\n{3,}/g, '\\n\\n')\n        .trim();\n      \n      console.log('Successfully constructed podcast data');\n      return podcastData;\n    } catch (parseError: any) {\n      console.error('Failed to parse podcast response:', parseError);\n      \n      // Fallback: create basic structure from response\n      console.log('Using fallback podcast structure');\n      return {\n        title: `${keyword} Podcast Episode`,\n        script: response,\n        duration: 18,\n        outline: [\"Introduction\", \"Main discussion\", \"Key insights\", \"Conclusion\"]\n      };\n    }\n  }\n\n  async generateBlog(keyword: string, research: any): Promise<any> {\n    console.log('Generating SEO-optimized blog for:', keyword);\n    console.log('Research data:', research);\n\n    const systemPrompt = `You are an expert SEO content writer who creates highly engaging, authoritative content that ranks well on Google. \n    You follow E-E-A-T principles and write content that demonstrates real expertise, experience, authority, and trustworthiness.\n    Your content is comprehensive, well-structured, and naturally incorporates keywords for optimal SEO performance.\n    \n    IMPORTANT: Write at an 8th-grade reading level using:\n    - Short sentences (15-20 words max)\n    - Simple, common words\n    - Active voice\n    - Clear, direct language\n    - One idea per sentence\n    - Avoid jargon unless necessary (and explain it when used)`;\n\n    // Build research summary from available data\n    let researchSummary = '';\n    if (research) {\n      if (research.definition) researchSummary += `\\nDefinition: ${research.definition}`;\n      if (research.overview) researchSummary += `\\nOverview: ${research.overview}`;\n      if (research.currentTrends) researchSummary += `\\nTrends: ${Array.isArray(research.currentTrends) ? research.currentTrends.join(', ') : research.currentTrends}`;\n      if (research.statistics) researchSummary += `\\nStatistics: ${JSON.stringify(research.statistics).slice(0, 500)}`;\n      if (research.commonQuestions) researchSummary += `\\nCommon Questions: ${JSON.stringify(research.commonQuestions).slice(0, 500)}`;\n      if (research.applications) researchSummary += `\\nApplications: ${Array.isArray(research.applications) ? research.applications.join(', ') : research.applications}`;\n    }\n\n    if (!researchSummary) {\n      researchSummary = JSON.stringify(research, null, 2).slice(0, 2000);\n    }\n\n    const userPrompt = `Create a comprehensive, SEO-optimized blog post about \"${keyword}\" using the provided research data.\n\nRESEARCH DATA:${researchSummary}\n\nBLOG POST REQUIREMENTS:\n\n1. Create a blog post that is 1,500-2,000 words long\n2. Include an SEO-optimized title that naturally includes \"${keyword}\"\n3. Write a compelling meta description (155-160 characters)\n4. Structure with:\n   - Engaging introduction with a hook\n   - 5-7 main sections with H2 headings\n   - Subsections with H3 headings where appropriate\n   - Conclusion with clear call-to-action\n\n5. SEO Optimization:\n   - Use \"${keyword}\" naturally 5-7 times throughout\n   - Include semantic variations and related terms\n   - Target potential featured snippets with clear, concise answers\n   - Write in an easy-to-read style (8th-grade level)\n\n6. READABILITY REQUIREMENTS (8th Grade Level):\n   - Use short sentences (15-20 words maximum)\n   - Choose simple, everyday words over complex ones\n   - Write in active voice (\"We tested\" not \"It was tested\")\n   - Break complex ideas into simple steps\n   - Use transition words (First, Next, However, Therefore)\n   - Define technical terms in simple language\n   - Use concrete examples to explain abstract concepts\n\n7. Demonstrate E-E-A-T:\n   - Show expertise through accurate information\n   - Include statistics and data points from the research\n   - Reference authoritative sources\n   - Provide practical, actionable advice\n\n8. Engagement:\n   - Use short paragraphs (2-3 sentences)\n   - Include bullet points and lists\n   - Add examples and analogies\n   - Keep the tone conversational but professional\n   - Ask rhetorical questions to engage readers\n   - Use \"you\" to speak directly to the reader\n\nFORMAT YOUR RESPONSE AS JSON:\n{\n  \"title\": \"SEO-optimized title with keyword\",\n  \"metaDescription\": \"Compelling meta description 155-160 characters with keyword\",\n  \"content\": \"Full blog post in Markdown format with ## for H2 and ### for H3 headings\",\n  \"wordCount\": 1800,\n  \"readingTime\": 8,\n  \"targetKeywords\": [\"main keyword\", \"related keyword 1\", \"related keyword 2\"],\n  \"readabilityScore\": \"Grade 8\"\n}\n\nRemember: Write clearly and simply. If a 13-year-old can understand it, you're doing it right.`;\n\n    const messages = [\n      { role: 'system', content: systemPrompt },\n      { role: 'user', content: userPrompt }\n    ];\n\n    const response = await this.makeRequest(messages);\n    \n    try {\n      console.log('Raw response length:', response.length);\n      console.log('Response preview:', response.substring(0, 500));\n      console.log('Character at position 509:', response.charCodeAt(509));\n      console.log('Context around position 509:', response.substring(500, 520));\n      \n      // Try a more aggressive approach - parse the response structure manually\n      let jsonString = response.trim();\n      \n      // If the response has markdown code blocks, extract the JSON from them\n      const codeBlockMatch = jsonString.match(/```(?:json)?\\s*(\\{[\\s\\S]*?\\})\\s*```/);\n      if (codeBlockMatch) {\n        jsonString = codeBlockMatch[1];\n      }\n      \n      // Extract fields using regex instead of trying to parse potentially broken JSON\n      const extractField = (fieldName: string, isLongText: boolean = false): string => {\n        const pattern = isLongText \n          ? new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([\\\\s\\\\S]*?)(?=\",\\\\s*\"|\"\\\\s*}|$)`, 'i')\n          : new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\"([^\"]*)\"`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          let value = match[1];\n          // Clean up the extracted value\n          value = value.replace(/\\\\\"/g, '\"'); // Unescape quotes\n          value = value.replace(/\\\\\\\\/g, '\\\\'); // Unescape backslashes\n          if (!isLongText) {\n            value = value.replace(/[\\n\\r\\t]/g, ' ').trim();\n          }\n          return value;\n        }\n        return '';\n      };\n      \n      const extractArray = (fieldName: string): string[] => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*\\\\[([^\\\\]]*)]`, 'i');\n        const match = jsonString.match(pattern);\n        if (match && match[1]) {\n          return match[1]\n            .split(',')\n            .map(s => s.trim().replace(/^[\"']|[\"']$/g, ''))\n            .filter(s => s);\n        }\n        return [];\n      };\n      \n      const extractNumber = (fieldName: string): number => {\n        const pattern = new RegExp(`\"${fieldName}\"\\\\s*:\\\\s*(\\\\d+)`, 'i');\n        const match = jsonString.match(pattern);\n        return match && match[1] ? parseInt(match[1]) : 0;\n      };\n      \n      // Manually construct the blog data object\n      const blogData = {\n        title: extractField('title') || `Expert Guide to ${keyword}`,\n        metaDescription: extractField('metaDescription') || `Comprehensive guide about ${keyword}. Learn everything you need to know.`,\n        content: extractField('content', true) || `# ${keyword}\\n\\nContent generation in progress...`,\n        wordCount: extractNumber('wordCount') || 1500,\n        readingTime: extractNumber('readingTime') || 8,\n        targetKeywords: extractArray('targetKeywords').length > 0 ? extractArray('targetKeywords') : [keyword],\n        readabilityScore: extractField('readabilityScore') || 'Grade 8'\n      };\n      \n      // Clean the content field to ensure it's valid markdown\n      blogData.content = blogData.content\n        .replace(/\\\\n/g, '\\n')\n        .replace(/\\\\r/g, '\\r')\n        .replace(/\\\\t/g, '\\t')\n        .replace(/\\n{3,}/g, '\\n\\n') // Limit consecutive newlines\n        .trim();\n      \n      // Ensure content has proper markdown structure\n      if (!blogData.content.includes('#')) {\n        blogData.content = `# ${blogData.title}\\n\\n${blogData.content}`;\n      }\n      \n      console.log('Successfully constructed blog data');\n      return blogData;\n    } catch (parseError: any) {\n      console.error('Failed to parse blog response:', parseError);\n      console.error('Parse error details:', {\n        message: parseError.message,\n        position: parseError.message.match(/position (\\d+)/)?.[1],\n        response: response.substring(0, 600) + '...'\n      });\n      \n      // Try to extract JSON from the response\n      const jsonMatch = response.match(/\\{[\\s\\S]*\\}/);\n      if (jsonMatch) {\n        try {\n          let cleanedExtract = jsonMatch[0];\n          \n          // Apply the same cleaning logic as above\n          cleanedExtract = cleanedExtract.replace(/\"content\"\\s*:\\s*\"([\\s\\S]*?)\"\\s*(?=,\\s*\"|\\s*\\})/g, (match, content) => {\n            let fixed = content;\n            fixed = fixed.replace(/\\\\/g, '\\\\\\\\');\n            fixed = fixed.replace(/([^\\\\])\"/g, '$1\\\\\"');\n            fixed = fixed.replace(/^\"/g, '\\\\\"');\n            fixed = fixed.replace(/([^\\\\])\\n/g, '$1\\\\n');\n            fixed = fixed.replace(/^\\n/g, '\\\\n');\n            fixed = fixed.replace(/([^\\\\])\\r/g, '$1\\\\r');\n            fixed = fixed.replace(/^\\r/g, '\\\\r');\n            fixed = fixed.replace(/([^\\\\])\\t/g, '$1\\\\t');\n            fixed = fixed.replace(/^\\t/g, '\\\\t');\n            return `\"content\": \"${fixed}\"`;\n          });\n          \n          // Clean other fields\n          cleanedExtract = cleanedExtract.replace(/\"(title|metaDescription)\"\\s*:\\s*\"([^\"\\\\]*(\\\\.[^\"\\\\]*)*)\"/g, (match, field, content) => {\n            const fixed = content.replace(/[\\n\\r\\t]/g, ' ').trim();\n            return `\"${field}\": \"${fixed}\"`;\n          });\n          \n          // Remove trailing commas and control characters\n          cleanedExtract = cleanedExtract.replace(/,\\s*([}\\]])/g, '$1');\n          cleanedExtract = cleanedExtract.replace(/[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]/g, '');\n          \n          const extracted = JSON.parse(cleanedExtract);\n          if (!extracted.wordCount) extracted.wordCount = 1500;\n          if (!extracted.readingTime) extracted.readingTime = 8;\n          if (!extracted.targetKeywords) extracted.targetKeywords = [keyword];\n          if (!extracted.readabilityScore) extracted.readabilityScore = \"Grade 8\";\n          return extracted;\n        } catch (e) {\n          console.error('Failed to parse extracted JSON:', e);\n        }\n      }\n      throw new Error('Failed to parse blog data: ' + parseError.message);\n    }\n  }\n}\n\nexport const perplexityService = new PerplexityService();"],"mappings":"AAAA;AACA,OAAOA,KAAK,MAAM,OAAO;AAGzB,MAAMC,kBAAkB,GAAG,4CAA4C;;AAEvE;AACA,MAAMC,mBAAmB,GAAGA,CAAA,KAAM;EAChC,OAAOC,OAAO,CAACC,GAAG,CAACC,4BAA4B;AACjD,CAAC;AAcD,OAAO,MAAMC,iBAAiB,CAAC;EAC7B,MAAcC,KAAKA,CAACC,EAAU,EAAiB;IAC7C,OAAO,IAAIC,OAAO,CAACC,OAAO,IAAIC,UAAU,CAACD,OAAO,EAAEF,EAAE,CAAC,CAAC;EACxD;EAEA,MAAcI,WAAWA,CAACC,QAAe,EAAEC,UAAkB,GAAG,CAAC,EAAmB;IAClFC,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC;IAC/C,MAAMC,MAAM,GAAGf,mBAAmB,CAAC,CAAC;IACpCa,OAAO,CAACC,GAAG,CAAC,iBAAiB,EAAE,CAAC,CAACC,MAAM,CAAC;IACxCF,OAAO,CAACC,GAAG,CAAC,gBAAgB,EAAEC,MAAM,GAAG,GAAGA,MAAM,CAACC,SAAS,CAAC,CAAC,EAAE,EAAE,CAAC,KAAK,GAAG,WAAW,CAAC;IACrFH,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAEH,QAAQ,CAACM,MAAM,CAAC;IAEhD,IAAI,CAACF,MAAM,EAAE;MACXF,OAAO,CAACK,KAAK,CAAC,wBAAwB,EAAE;QACtCf,4BAA4B,EAAEF,OAAO,CAACC,GAAG,CAACC,4BAA4B;QACtEgB,UAAU,EAAEC,MAAM,CAACC,IAAI,CAACpB,OAAO,CAACC,GAAG,CAAC,CAACoB,MAAM,CAACC,GAAG,IAAIA,GAAG,CAACC,UAAU,CAAC,YAAY,CAAC;MACjF,CAAC,CAAC;MACF,MAAM,IAAIC,KAAK,CAAC,oEAAoE,CAAC;IACvF;IAEA,IAAI;MACF,MAAMC,WAAW,GAAG;QAClBC,KAAK,EAAE,WAAW;QAClBhB,QAAQ;QACRiB,WAAW,EAAE,GAAG;QAChBC,UAAU,EAAE;MACd,CAAC;MAEDhB,OAAO,CAACC,GAAG,CAAC,2CAA2C,CAAC;MAExD,MAAMgB,QAAQ,GAAG,MAAMhC,KAAK,CAACiC,IAAI,CAC/BhC,kBAAkB,EAClB2B,WAAW,EACX;QACEM,OAAO,EAAE;UACP,eAAe,EAAE,UAAUjB,MAAM,EAAE;UACnC,cAAc,EAAE;QAClB,CAAC;QACDkB,OAAO,EAAE,MAAM,CAAE;MACnB,CACF,CAAC;MAEDpB,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEgB,QAAQ,CAACI,MAAM,CAAC;MAC9DrB,OAAO,CAACC,GAAG,CAAC,0BAA0B,EAAEM,MAAM,CAACC,IAAI,CAACS,QAAQ,CAACK,IAAI,CAAC,CAAC;MAEnE,IAAI,CAACL,QAAQ,CAACK,IAAI,CAACC,OAAO,IAAI,CAACN,QAAQ,CAACK,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,EAAE;QACvD,MAAM,IAAIX,KAAK,CAAC,gCAAgC,CAAC;MACnD;MAEA,OAAOK,QAAQ,CAACK,IAAI,CAACC,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACC,OAAO;IACjD,CAAC,CAAC,OAAOpB,KAAU,EAAE;MAAA,IAAAqB,eAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,gBAAA,EAAAC,qBAAA,EAAAC,sBAAA;MACnBjC,OAAO,CAACK,KAAK,CAAC,+BAA+B,EAAE;QAC7CmB,OAAO,EAAEnB,KAAK,CAACmB,OAAO;QACtBP,QAAQ,GAAAS,eAAA,GAAErB,KAAK,CAACY,QAAQ,cAAAS,eAAA,uBAAdA,eAAA,CAAgBJ,IAAI;QAC9BD,MAAM,GAAAM,gBAAA,GAAEtB,KAAK,CAACY,QAAQ,cAAAU,gBAAA,uBAAdA,gBAAA,CAAgBN,MAAM;QAC9Ba,SAAS,EAAE7B,KAAK,CAAC8B,IAAI,KAAK,cAAc;QACxCpC;MACF,CAAC,CAAC;;MAEF;MACA,MAAMqC,UAAU,GAAG,CAAC;MACpB,MAAMC,WAAW,GAAGtC,UAAU,GAAGqC,UAAU,KACzC,EAAAR,gBAAA,GAAAvB,KAAK,CAACY,QAAQ,cAAAW,gBAAA,uBAAdA,gBAAA,CAAgBP,MAAM,MAAK,GAAG;MAAI;MAClC,EAAAQ,gBAAA,GAAAxB,KAAK,CAACY,QAAQ,cAAAY,gBAAA,uBAAdA,gBAAA,CAAgBR,MAAM,MAAK,GAAG;MAAI;MAClC,EAAAS,gBAAA,GAAAzB,KAAK,CAACY,QAAQ,cAAAa,gBAAA,uBAAdA,gBAAA,CAAgBT,MAAM,MAAK,GAAG;MAAI;MAClChB,KAAK,CAAC8B,IAAI,KAAK,cAAc;MAAK;MAClC9B,KAAK,CAAC8B,IAAI,KAAK,WAAW;MAAS;MACnC9B,KAAK,CAAC8B,IAAI,KAAK,cAAc,CAAM;MAAA,CACpC;MAED,IAAIE,WAAW,EAAE;QACf,MAAMC,OAAO,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,EAAEzC,UAAU,CAAC,GAAG,IAAI,CAAC,CAAC;QAChDC,OAAO,CAACC,GAAG,CAAC,eAAeqC,OAAO,kBAAkBvC,UAAU,GAAG,CAAC,IAAIqC,UAAU,GAAG,CAAC;QACpF,MAAM,IAAI,CAAC5C,KAAK,CAAC8C,OAAO,CAAC;QACzB,OAAO,IAAI,CAACzC,WAAW,CAACC,QAAQ,EAAEC,UAAU,GAAG,CAAC,CAAC;MACnD;MAEA,IAAIM,KAAK,CAAC8B,IAAI,KAAK,cAAc,EAAE;QACjC,MAAM,IAAIvB,KAAK,CAAC,sCAAsC,CAAC;MACzD;MAEA,MAAM,IAAIA,KAAK,CAAC,EAAAmB,gBAAA,GAAA1B,KAAK,CAACY,QAAQ,cAAAc,gBAAA,wBAAAC,qBAAA,GAAdD,gBAAA,CAAgBT,IAAI,cAAAU,qBAAA,wBAAAC,sBAAA,GAApBD,qBAAA,CAAsB3B,KAAK,cAAA4B,sBAAA,uBAA3BA,sBAAA,CAA6BT,OAAO,KAAInB,KAAK,CAACmB,OAAO,IAAI,6BAA6B,CAAC;IACzG;EACF;EAEA,MAAMiB,gBAAgBA,CAACC,OAAe,EAA4B;IAChE1C,OAAO,CAAC2C,IAAI,CAAC,0BAA0B,CAAC;IACxC3C,OAAO,CAACC,GAAG,CAAC,mCAAmC,EAAEyC,OAAO,CAAC;IAEzD,MAAME,YAAY,GAAG;AACzB;AACA,yHAAyH;IAErH,MAAMC,UAAU,GAAG,aAAaH,OAAO;AAC3C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,uCAAuCA,OAAO;AAC9C;AACA;AACA;AACA;AACA,4BAA4BA,OAAO;AACnC,6BAA6BA,OAAO;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,wBAAwB;IAEpB,MAAM5C,QAAQ,GAAG,CACf;MAAEgD,IAAI,EAAE,QAAQ;MAAErB,OAAO,EAAEmB;IAAa,CAAC,EACzC;MAAEE,IAAI,EAAE,MAAM;MAAErB,OAAO,EAAEoB;IAAW,CAAC,CACtC;IAED,MAAM5B,QAAQ,GAAG,MAAM,IAAI,CAACpB,WAAW,CAACC,QAAQ,CAAC;IACjDE,OAAO,CAAC+C,OAAO,CAAC,0BAA0B,CAAC;IAC3C/C,OAAO,CAACC,GAAG,CAAC,uCAAuC,EAAEgB,QAAQ,CAACb,MAAM,CAAC;IAErE,IAAI;MACF,MAAM4C,YAAY,GAAGC,IAAI,CAACC,KAAK,CAACjC,QAAQ,CAAC;MACzCjB,OAAO,CAACC,GAAG,CAAC,mCAAmC,CAAC;MAChD,OAAO+C,YAAY;IACrB,CAAC,CAAC,OAAOG,UAAU,EAAE;MACnBnD,OAAO,CAAC+C,OAAO,CAAC,0BAA0B,CAAC;MAC3C/C,OAAO,CAACK,KAAK,CAAC,oCAAoC,EAAE8C,UAAU,CAAC;MAC/DnD,OAAO,CAACC,GAAG,CAAC,eAAe,EAAEgB,QAAQ,CAACd,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG,KAAK,CAAC;MAChE,MAAMiD,SAAS,GAAGnC,QAAQ,CAACoC,KAAK,CAAC,aAAa,CAAC;MAC/C,IAAID,SAAS,EAAE;QACb,OAAOH,IAAI,CAACC,KAAK,CAACE,SAAS,CAAC,CAAC,CAAC,CAAC;MACjC;MACA,MAAM,IAAIxC,KAAK,CAAC,+BAA+B,CAAC;IAClD;EACF;EAEA,MAAM0C,qBAAqBA,CAACZ,OAAe,EAAEa,QAAa,EAAEC,IAAS,EAAgB;IAAA,IAAAC,aAAA;IACnFzD,OAAO,CAACC,GAAG,CAAC,gCAAgC,EAAEyC,OAAO,CAAC;IACtD1C,OAAO,CAACC,GAAG,CAAC,sBAAsB,EAAE,CAAAuD,IAAI,aAAJA,IAAI,wBAAAC,aAAA,GAAJD,IAAI,CAAE/B,OAAO,cAAAgC,aAAA,uBAAbA,aAAA,CAAerD,MAAM,KAAI,CAAC,CAAC;IAC/DJ,OAAO,CAACC,GAAG,CAAC,gBAAgB,EAAEsD,QAAQ,GAAGhD,MAAM,CAACC,IAAI,CAAC+C,QAAQ,CAAC,GAAG,aAAa,CAAC;IAE/E,MAAMX,YAAY,GAAG;AACzB;AACA,oNAAoN;;IAEhN;IACA,MAAMc,WAAW,GAAGF,IAAI,aAAJA,IAAI,eAAJA,IAAI,CAAE/B,OAAO,GAAG+B,IAAI,CAAC/B,OAAO,CAACtB,SAAS,CAAC,CAAC,EAAE,IAAI,CAAC,GAAG,EAAE;;IAExE;IACA,IAAIwD,gBAAgB,GAAG,EAAE;IACzB,IAAIJ,QAAQ,EAAE;MACZ,IAAIA,QAAQ,CAACK,UAAU,EAAED,gBAAgB,IAAI,qBAAqBJ,QAAQ,CAACK,UAAU,EAAE;MACvF,IAAIL,QAAQ,CAACM,aAAa,EAAEF,gBAAgB,IAAI,aAAaG,KAAK,CAACC,OAAO,CAACR,QAAQ,CAACM,aAAa,CAAC,GAAGN,QAAQ,CAACM,aAAa,CAACG,IAAI,CAAC,IAAI,CAAC,GAAGT,QAAQ,CAACM,aAAa,EAAE;MACjK,IAAIN,QAAQ,CAACU,UAAU,IAAIH,KAAK,CAACC,OAAO,CAACR,QAAQ,CAACU,UAAU,CAAC,EAAE;QAC7DN,gBAAgB,IAAI,iBAAiBJ,QAAQ,CAACU,UAAU,CAACC,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAACC,GAAG,CAAEC,IAAS,IACjF,OAAOA,IAAI,KAAK,QAAQ,GAAG,GAAGA,IAAI,CAACC,MAAM,KAAKD,IAAI,CAACE,KAAK,EAAE,GAAGF,IAC/D,CAAC,CAACJ,IAAI,CAAC,IAAI,CAAC,EAAE;MAChB;MACA,IAAIT,QAAQ,CAACgB,YAAY,EAAEZ,gBAAgB,IAAI,mBAAmBG,KAAK,CAACC,OAAO,CAACR,QAAQ,CAACgB,YAAY,CAAC,GAAGhB,QAAQ,CAACgB,YAAY,CAACP,IAAI,CAAC,IAAI,CAAC,GAAGT,QAAQ,CAACgB,YAAY,EAAE;IACrK;IAEA,MAAM1B,UAAU,GAAG,4CAA4CH,OAAO;AAC1E;AACA;AACA,EAAEgB,WAAW;AACb;AACA,oBAAoBC,gBAAgB;AACpC;AACA,gCAAgCjB,OAAO;AACvC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,0FAA0FA,OAAO,8BAA8B;IAE3H,MAAM5C,QAAQ,GAAG,CACf;MAAEgD,IAAI,EAAE,QAAQ;MAAErB,OAAO,EAAEmB;IAAa,CAAC,EACzC;MAAEE,IAAI,EAAE,MAAM;MAAErB,OAAO,EAAEoB;IAAW,CAAC,CACtC;IAED,MAAM5B,QAAQ,GAAG,MAAM,IAAI,CAACpB,WAAW,CAACC,QAAQ,CAAC;IAEjD,IAAI;MACFE,OAAO,CAACC,GAAG,CAAC,8BAA8B,EAAEgB,QAAQ,CAACb,MAAM,CAAC;MAC5DJ,OAAO,CAACC,GAAG,CAAC,mBAAmB,EAAEgB,QAAQ,CAACd,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC;;MAE5D;MACA,IAAIqE,UAAU,GAAGvD,QAAQ,CAACwD,IAAI,CAAC,CAAC;;MAEhC;MACA,MAAMC,cAAc,GAAGF,UAAU,CAACnB,KAAK,CAAC,qCAAqC,CAAC;MAC9E,IAAIqB,cAAc,EAAE;QAClBF,UAAU,GAAGE,cAAc,CAAC,CAAC,CAAC;MAChC;;MAEA;MACA,MAAMC,YAAY,GAAGA,CAACC,SAAiB,EAAEC,UAAmB,GAAG,KAAK,KAAa;QAC/E,MAAMC,OAAO,GAAGD,UAAU,GACtB,IAAIE,MAAM,CAAC,IAAIH,SAAS,6CAA6C,EAAE,GAAG,CAAC,GAC3E,IAAIG,MAAM,CAAC,IAAIH,SAAS,qBAAqB,EAAE,GAAG,CAAC;QACvD,MAAMvB,KAAK,GAAGmB,UAAU,CAACnB,KAAK,CAACyB,OAAO,CAAC;QACvC,IAAIzB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,EAAE;UACrB,IAAIiB,KAAK,GAAGjB,KAAK,CAAC,CAAC,CAAC;UACpB;UACAiB,KAAK,GAAGA,KAAK,CAACU,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC,CAAC;UACpCV,KAAK,GAAGA,KAAK,CAACU,OAAO,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC,CAAC;UACtC,IAAI,CAACH,UAAU,EAAE;YACfP,KAAK,GAAGA,KAAK,CAACU,OAAO,CAAC,WAAW,EAAE,GAAG,CAAC,CAACP,IAAI,CAAC,CAAC;UAChD;UACA,OAAOH,KAAK;QACd;QACA,OAAO,EAAE;MACX,CAAC;MAED,MAAMW,YAAY,GAAIL,SAAiB,IAAe;QACpD,MAAME,OAAO,GAAG,IAAIC,MAAM,CAAC,IAAIH,SAAS,yBAAyB,EAAE,GAAG,CAAC;QACvE,MAAMvB,KAAK,GAAGmB,UAAU,CAACnB,KAAK,CAACyB,OAAO,CAAC;QACvC,IAAIzB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,EAAE;UACrB,OAAOA,KAAK,CAAC,CAAC,CAAC,CACZ6B,KAAK,CAAC,GAAG,CAAC,CACVf,GAAG,CAACgB,CAAC,IAAIA,CAAC,CAACV,IAAI,CAAC,CAAC,CAACO,OAAO,CAAC,cAAc,EAAE,EAAE,CAAC,CAAC,CAC9CvE,MAAM,CAAC0E,CAAC,IAAIA,CAAC,CAAC;QACnB;QACA,OAAO,EAAE;MACX,CAAC;MAED,MAAMC,aAAa,GAAIR,SAAiB,IAAa;QACnD,MAAME,OAAO,GAAG,IAAIC,MAAM,CAAC,IAAIH,SAAS,kBAAkB,EAAE,GAAG,CAAC;QAChE,MAAMvB,KAAK,GAAGmB,UAAU,CAACnB,KAAK,CAACyB,OAAO,CAAC;QACvC,OAAOzB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,GAAGgC,QAAQ,CAAChC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,EAAE;MACpD,CAAC;;MAED;MACA,MAAMiC,WAAW,GAAG;QAClBC,KAAK,EAAEZ,YAAY,CAAC,OAAO,CAAC,IAAI,GAAGjC,OAAO,kBAAkB;QAC5D8C,MAAM,EAAEb,YAAY,CAAC,QAAQ,EAAE,IAAI,CAAC,IAAI,KAAKjC,OAAO,uDAAuDA,OAAO,KAAK;QACvH+C,QAAQ,EAAEL,aAAa,CAAC,UAAU,CAAC,IAAI,EAAE;QACzCM,OAAO,EAAET,YAAY,CAAC,SAAS,CAAC,CAAC7E,MAAM,GAAG,CAAC,GAAG6E,YAAY,CAAC,SAAS,CAAC,GAAG,CACtE,uBAAuB,EACvB,qBAAqB,EACrB,cAAc,EACd,0BAA0B;MAE9B,CAAC;;MAED;MACAK,WAAW,CAACE,MAAM,GAAGF,WAAW,CAACE,MAAM,CACpCR,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,SAAS,EAAE,MAAM,CAAC,CAC1BP,IAAI,CAAC,CAAC;MAETzE,OAAO,CAACC,GAAG,CAAC,uCAAuC,CAAC;MACpD,OAAOqF,WAAW;IACpB,CAAC,CAAC,OAAOnC,UAAe,EAAE;MACxBnD,OAAO,CAACK,KAAK,CAAC,mCAAmC,EAAE8C,UAAU,CAAC;;MAE9D;MACAnD,OAAO,CAACC,GAAG,CAAC,kCAAkC,CAAC;MAC/C,OAAO;QACLsF,KAAK,EAAE,GAAG7C,OAAO,kBAAkB;QACnC8C,MAAM,EAAEvE,QAAQ;QAChBwE,QAAQ,EAAE,EAAE;QACZC,OAAO,EAAE,CAAC,cAAc,EAAE,iBAAiB,EAAE,cAAc,EAAE,YAAY;MAC3E,CAAC;IACH;EACF;EAEA,MAAMC,YAAYA,CAACjD,OAAe,EAAEa,QAAa,EAAgB;IAC/DvD,OAAO,CAACC,GAAG,CAAC,oCAAoC,EAAEyC,OAAO,CAAC;IAC1D1C,OAAO,CAACC,GAAG,CAAC,gBAAgB,EAAEsD,QAAQ,CAAC;IAEvC,MAAMX,YAAY,GAAG;AACzB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+DAA+D;;IAE3D;IACA,IAAIgD,eAAe,GAAG,EAAE;IACxB,IAAIrC,QAAQ,EAAE;MACZ,IAAIA,QAAQ,CAACK,UAAU,EAAEgC,eAAe,IAAI,iBAAiBrC,QAAQ,CAACK,UAAU,EAAE;MAClF,IAAIL,QAAQ,CAACsC,QAAQ,EAAED,eAAe,IAAI,eAAerC,QAAQ,CAACsC,QAAQ,EAAE;MAC5E,IAAItC,QAAQ,CAACM,aAAa,EAAE+B,eAAe,IAAI,aAAa9B,KAAK,CAACC,OAAO,CAACR,QAAQ,CAACM,aAAa,CAAC,GAAGN,QAAQ,CAACM,aAAa,CAACG,IAAI,CAAC,IAAI,CAAC,GAAGT,QAAQ,CAACM,aAAa,EAAE;MAChK,IAAIN,QAAQ,CAACU,UAAU,EAAE2B,eAAe,IAAI,iBAAiB3C,IAAI,CAAC6C,SAAS,CAACvC,QAAQ,CAACU,UAAU,CAAC,CAACC,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE;MAChH,IAAIX,QAAQ,CAACwC,eAAe,EAAEH,eAAe,IAAI,uBAAuB3C,IAAI,CAAC6C,SAAS,CAACvC,QAAQ,CAACwC,eAAe,CAAC,CAAC7B,KAAK,CAAC,CAAC,EAAE,GAAG,CAAC,EAAE;MAChI,IAAIX,QAAQ,CAACgB,YAAY,EAAEqB,eAAe,IAAI,mBAAmB9B,KAAK,CAACC,OAAO,CAACR,QAAQ,CAACgB,YAAY,CAAC,GAAGhB,QAAQ,CAACgB,YAAY,CAACP,IAAI,CAAC,IAAI,CAAC,GAAGT,QAAQ,CAACgB,YAAY,EAAE;IACpK;IAEA,IAAI,CAACqB,eAAe,EAAE;MACpBA,eAAe,GAAG3C,IAAI,CAAC6C,SAAS,CAACvC,QAAQ,EAAE,IAAI,EAAE,CAAC,CAAC,CAACW,KAAK,CAAC,CAAC,EAAE,IAAI,CAAC;IACpE;IAEA,MAAMrB,UAAU,GAAG,0DAA0DH,OAAO;AACxF;AACA,gBAAgBkD,eAAe;AAC/B;AACA;AACA;AACA;AACA,6DAA6DlD,OAAO;AACpE;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,YAAYA,OAAO;AACnB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,+FAA+F;IAE3F,MAAM5C,QAAQ,GAAG,CACf;MAAEgD,IAAI,EAAE,QAAQ;MAAErB,OAAO,EAAEmB;IAAa,CAAC,EACzC;MAAEE,IAAI,EAAE,MAAM;MAAErB,OAAO,EAAEoB;IAAW,CAAC,CACtC;IAED,MAAM5B,QAAQ,GAAG,MAAM,IAAI,CAACpB,WAAW,CAACC,QAAQ,CAAC;IAEjD,IAAI;MACFE,OAAO,CAACC,GAAG,CAAC,sBAAsB,EAAEgB,QAAQ,CAACb,MAAM,CAAC;MACpDJ,OAAO,CAACC,GAAG,CAAC,mBAAmB,EAAEgB,QAAQ,CAACd,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,CAAC;MAC5DH,OAAO,CAACC,GAAG,CAAC,4BAA4B,EAAEgB,QAAQ,CAAC+E,UAAU,CAAC,GAAG,CAAC,CAAC;MACnEhG,OAAO,CAACC,GAAG,CAAC,8BAA8B,EAAEgB,QAAQ,CAACd,SAAS,CAAC,GAAG,EAAE,GAAG,CAAC,CAAC;;MAEzE;MACA,IAAIqE,UAAU,GAAGvD,QAAQ,CAACwD,IAAI,CAAC,CAAC;;MAEhC;MACA,MAAMC,cAAc,GAAGF,UAAU,CAACnB,KAAK,CAAC,qCAAqC,CAAC;MAC9E,IAAIqB,cAAc,EAAE;QAClBF,UAAU,GAAGE,cAAc,CAAC,CAAC,CAAC;MAChC;;MAEA;MACA,MAAMC,YAAY,GAAGA,CAACC,SAAiB,EAAEC,UAAmB,GAAG,KAAK,KAAa;QAC/E,MAAMC,OAAO,GAAGD,UAAU,GACtB,IAAIE,MAAM,CAAC,IAAIH,SAAS,6CAA6C,EAAE,GAAG,CAAC,GAC3E,IAAIG,MAAM,CAAC,IAAIH,SAAS,qBAAqB,EAAE,GAAG,CAAC;QACvD,MAAMvB,KAAK,GAAGmB,UAAU,CAACnB,KAAK,CAACyB,OAAO,CAAC;QACvC,IAAIzB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,EAAE;UACrB,IAAIiB,KAAK,GAAGjB,KAAK,CAAC,CAAC,CAAC;UACpB;UACAiB,KAAK,GAAGA,KAAK,CAACU,OAAO,CAAC,MAAM,EAAE,GAAG,CAAC,CAAC,CAAC;UACpCV,KAAK,GAAGA,KAAK,CAACU,OAAO,CAAC,OAAO,EAAE,IAAI,CAAC,CAAC,CAAC;UACtC,IAAI,CAACH,UAAU,EAAE;YACfP,KAAK,GAAGA,KAAK,CAACU,OAAO,CAAC,WAAW,EAAE,GAAG,CAAC,CAACP,IAAI,CAAC,CAAC;UAChD;UACA,OAAOH,KAAK;QACd;QACA,OAAO,EAAE;MACX,CAAC;MAED,MAAMW,YAAY,GAAIL,SAAiB,IAAe;QACpD,MAAME,OAAO,GAAG,IAAIC,MAAM,CAAC,IAAIH,SAAS,yBAAyB,EAAE,GAAG,CAAC;QACvE,MAAMvB,KAAK,GAAGmB,UAAU,CAACnB,KAAK,CAACyB,OAAO,CAAC;QACvC,IAAIzB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,EAAE;UACrB,OAAOA,KAAK,CAAC,CAAC,CAAC,CACZ6B,KAAK,CAAC,GAAG,CAAC,CACVf,GAAG,CAACgB,CAAC,IAAIA,CAAC,CAACV,IAAI,CAAC,CAAC,CAACO,OAAO,CAAC,cAAc,EAAE,EAAE,CAAC,CAAC,CAC9CvE,MAAM,CAAC0E,CAAC,IAAIA,CAAC,CAAC;QACnB;QACA,OAAO,EAAE;MACX,CAAC;MAED,MAAMC,aAAa,GAAIR,SAAiB,IAAa;QACnD,MAAME,OAAO,GAAG,IAAIC,MAAM,CAAC,IAAIH,SAAS,kBAAkB,EAAE,GAAG,CAAC;QAChE,MAAMvB,KAAK,GAAGmB,UAAU,CAACnB,KAAK,CAACyB,OAAO,CAAC;QACvC,OAAOzB,KAAK,IAAIA,KAAK,CAAC,CAAC,CAAC,GAAGgC,QAAQ,CAAChC,KAAK,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC;MACnD,CAAC;;MAED;MACA,MAAM4C,QAAQ,GAAG;QACfV,KAAK,EAAEZ,YAAY,CAAC,OAAO,CAAC,IAAI,mBAAmBjC,OAAO,EAAE;QAC5DwD,eAAe,EAAEvB,YAAY,CAAC,iBAAiB,CAAC,IAAI,6BAA6BjC,OAAO,sCAAsC;QAC9HjB,OAAO,EAAEkD,YAAY,CAAC,SAAS,EAAE,IAAI,CAAC,IAAI,KAAKjC,OAAO,uCAAuC;QAC7FyD,SAAS,EAAEf,aAAa,CAAC,WAAW,CAAC,IAAI,IAAI;QAC7CgB,WAAW,EAAEhB,aAAa,CAAC,aAAa,CAAC,IAAI,CAAC;QAC9CiB,cAAc,EAAEpB,YAAY,CAAC,gBAAgB,CAAC,CAAC7E,MAAM,GAAG,CAAC,GAAG6E,YAAY,CAAC,gBAAgB,CAAC,GAAG,CAACvC,OAAO,CAAC;QACtG4D,gBAAgB,EAAE3B,YAAY,CAAC,kBAAkB,CAAC,IAAI;MACxD,CAAC;;MAED;MACAsB,QAAQ,CAACxE,OAAO,GAAGwE,QAAQ,CAACxE,OAAO,CAChCuD,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,MAAM,EAAE,IAAI,CAAC,CACrBA,OAAO,CAAC,SAAS,EAAE,MAAM,CAAC,CAAC;MAAA,CAC3BP,IAAI,CAAC,CAAC;;MAET;MACA,IAAI,CAACwB,QAAQ,CAACxE,OAAO,CAAC8E,QAAQ,CAAC,GAAG,CAAC,EAAE;QACnCN,QAAQ,CAACxE,OAAO,GAAG,KAAKwE,QAAQ,CAACV,KAAK,OAAOU,QAAQ,CAACxE,OAAO,EAAE;MACjE;MAEAzB,OAAO,CAACC,GAAG,CAAC,oCAAoC,CAAC;MACjD,OAAOgG,QAAQ;IACjB,CAAC,CAAC,OAAO9C,UAAe,EAAE;MAAA,IAAAqD,qBAAA;MACxBxG,OAAO,CAACK,KAAK,CAAC,gCAAgC,EAAE8C,UAAU,CAAC;MAC3DnD,OAAO,CAACK,KAAK,CAAC,sBAAsB,EAAE;QACpCmB,OAAO,EAAE2B,UAAU,CAAC3B,OAAO;QAC3BiF,QAAQ,GAAAD,qBAAA,GAAErD,UAAU,CAAC3B,OAAO,CAAC6B,KAAK,CAAC,gBAAgB,CAAC,cAAAmD,qBAAA,uBAA1CA,qBAAA,CAA6C,CAAC,CAAC;QACzDvF,QAAQ,EAAEA,QAAQ,CAACd,SAAS,CAAC,CAAC,EAAE,GAAG,CAAC,GAAG;MACzC,CAAC,CAAC;;MAEF;MACA,MAAMiD,SAAS,GAAGnC,QAAQ,CAACoC,KAAK,CAAC,aAAa,CAAC;MAC/C,IAAID,SAAS,EAAE;QACb,IAAI;UACF,IAAIsD,cAAc,GAAGtD,SAAS,CAAC,CAAC,CAAC;;UAEjC;UACAsD,cAAc,GAAGA,cAAc,CAAC1B,OAAO,CAAC,iDAAiD,EAAE,CAAC3B,KAAK,EAAE5B,OAAO,KAAK;YAC7G,IAAIkF,KAAK,GAAGlF,OAAO;YACnBkF,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,KAAK,EAAE,MAAM,CAAC;YACpC2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,WAAW,EAAE,OAAO,CAAC;YAC3C2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,KAAK,EAAE,KAAK,CAAC;YACnC2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,YAAY,EAAE,OAAO,CAAC;YAC5C2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,MAAM,EAAE,KAAK,CAAC;YACpC2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,YAAY,EAAE,OAAO,CAAC;YAC5C2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,MAAM,EAAE,KAAK,CAAC;YACpC2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,YAAY,EAAE,OAAO,CAAC;YAC5C2B,KAAK,GAAGA,KAAK,CAAC3B,OAAO,CAAC,MAAM,EAAE,KAAK,CAAC;YACpC,OAAO,eAAe2B,KAAK,GAAG;UAChC,CAAC,CAAC;;UAEF;UACAD,cAAc,GAAGA,cAAc,CAAC1B,OAAO,CAAC,2DAA2D,EAAE,CAAC3B,KAAK,EAAEuD,KAAK,EAAEnF,OAAO,KAAK;YAC9H,MAAMkF,KAAK,GAAGlF,OAAO,CAACuD,OAAO,CAAC,WAAW,EAAE,GAAG,CAAC,CAACP,IAAI,CAAC,CAAC;YACtD,OAAO,IAAImC,KAAK,OAAOD,KAAK,GAAG;UACjC,CAAC,CAAC;;UAEF;UACAD,cAAc,GAAGA,cAAc,CAAC1B,OAAO,CAAC,cAAc,EAAE,IAAI,CAAC;UAC7D0B,cAAc,GAAGA,cAAc,CAAC1B,OAAO,CAAC,mCAAmC,EAAE,EAAE,CAAC;UAEhF,MAAM6B,SAAS,GAAG5D,IAAI,CAACC,KAAK,CAACwD,cAAc,CAAC;UAC5C,IAAI,CAACG,SAAS,CAACV,SAAS,EAAEU,SAAS,CAACV,SAAS,GAAG,IAAI;UACpD,IAAI,CAACU,SAAS,CAACT,WAAW,EAAES,SAAS,CAACT,WAAW,GAAG,CAAC;UACrD,IAAI,CAACS,SAAS,CAACR,cAAc,EAAEQ,SAAS,CAACR,cAAc,GAAG,CAAC3D,OAAO,CAAC;UACnE,IAAI,CAACmE,SAAS,CAACP,gBAAgB,EAAEO,SAAS,CAACP,gBAAgB,GAAG,SAAS;UACvE,OAAOO,SAAS;QAClB,CAAC,CAAC,OAAOC,CAAC,EAAE;UACV9G,OAAO,CAACK,KAAK,CAAC,iCAAiC,EAAEyG,CAAC,CAAC;QACrD;MACF;MACA,MAAM,IAAIlG,KAAK,CAAC,6BAA6B,GAAGuC,UAAU,CAAC3B,OAAO,CAAC;IACrE;EACF;AACF;AAEA,OAAO,MAAMuF,iBAAiB,GAAG,IAAIxH,iBAAiB,CAAC,CAAC","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}